# 点点点

# 二叉树

## 二叉树（Binary Tree）定义



> 定义：一棵二叉树是结点的一个有限集合，该集合或者为空，或者是由一个根结点加上两棵分别称为左子树和右子树的、互不相交的二叉树组成。
>
> 特点：每个结点至多只有两棵子树（二叉树中不存在度大于2的结点）
>
> 五种形态：

![img](https://img-blog.csdn.net/20160529151724567)



## 二叉树主要性质推导

1、若规定根节点的层数为1，则一棵非空二叉树的第i层上最多有2^(i-1) 个结点.

![image-20210611110948581](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210611111013.png)

2、若规定根节点的层数为1，则深度为h的二叉树的最大结点数是2^h- 1.

```json
证明：由性质1知二叉树每一层最大结点数个数。
因为一共有k层，所以有结点个数n=2^0+2^1+...+2^(k-1)
等比数列求和得n=2^k-1

```

3、对任何一棵二叉树, 如果度为0其叶结点个数为 n0, 度为2的分支结点个数为 n2,则有n0＝n2＋1

![image-20210611111026359](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210611111026.png)

4、包含n个结点的二叉树的高度至少为**log2 (n+1)**。. (ps：Log(n+1)是log以2为
底，n+1为对数)

![image-20210611111040047](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210611111040.png)

5、对于具有n个结点的**完全二叉树**，如果按照从上至下从左至右的数组顺序对所有节点从0开始编号，则对
于序号为i的结点有：
若i>0，i位置节点的 双亲序号：(i-1)/2；i=0，i为根节点编号，无双亲节点
若2i+1<n，左孩子序号：2i+1，2i+1>=n 否则无左孩子
若2i+2<n，右孩子序号：2i+2，2i+2>=n 否则无右孩子

![image-20210611111101025](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210611111101.png)



# 等比数列公式

![img](https://pics6.baidu.com/feed/023b5bb5c9ea15ce7db5a5b81f5acef53b87b28d.png?token=25a70aaebf6d71632f84a2e84a1f3abd)

# HashMap

**史上最详细的 JDK 1.8 HashMap 源码解析**

https://joonwhee.blog.csdn.net/article/details/78996181?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-13.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-13.control





## 1、[tableSizeFor](https://www.cnblogs.com/shujiying/p/12460808.html)

```java
  static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```

这个方法被调用的地方：

```java
    public HashMap(int initialCapacity, float loadFactor) {
        /**省略此处代码**/
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }
```

由此可以看到，当在实例化HashMap实例时，如果给定了initialCapacity，由于HashMap的capacity都是2的幂，因此这个方法用于找到大于等于initialCapacity的最小的2的幂（initialCapacity如果就是2的幂，则返回的还是这个数）。 
下面分析这个[算法](http://lib.csdn.net/base/datastructure)： 
首先，为什么要对cap做减1操作。`int n = cap - 1;` 
这是为了防止，cap已经是2的幂。如果cap已经是2的幂， 又没有执行这个减1操作，则执行完后面的几条无符号右移操作之后，返回的capacity将是这个cap的2倍。如果不懂，要看完后面的几个无符号右移之后再回来看看。让cap-1再赋值给n的目的是另找到的目标值大于或等于原值。例如二进制1000，十进制数值为8。如果不对它减1而直接操作，将得到答案10000，即16。显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。

HashMap里的MAXIMUM_CAPACITY是230。我结合tableSizeFor()的实现，猜测设置原因如下：
 int的正数最大可达231-1，而没办法取到231。所以容量也无法达到231。又需要让容量满足2的幂次。所以设置为230。

下面看看这几个无符号右移操作： 
如果n这时为0了（经过了cap-1之后），则经过后面的几次无符号右移依然是0，最后返回的capacity是1（最后有个n+1的操作）。 
这里只讨论n不等于0的情况。 
**第一次右移**

```java
n |= n >>> 1;
```

由于n不等于0，则n的二进制表示中总会有一bit为1，这时考虑最高位的1。通过无符号右移1位，则将最高位的1右移了1位，再做或操作，使得n的二进制表示中与最高位的1紧邻的右边一位也为1，如000011xxxxxx。 
**第二次右移**

```java
n |= n >>> 2;
```

注意，这个n已经经过了`n |= n >>> 1;` 操作。假设此时n为000011xxxxxx ，则n无符号右移两位，会将最高位两个连续的1右移两位，然后再与原来的n做或操作，这样n的二进制表示的高位中会有4个连续的1。如00001111xxxxxx 。 
**第三次右移**

```java
n |= n >>> 4;
```

这次把已经有的高位中的连续的4个1，右移4位，再做或操作，这样n的二进制表示的高位中会有8个连续的1。如00001111 1111xxxxxx 。 
**以此类推** 
注意，容量最大也就是32bit的正数，因此最后`n |= n >>> 16;` ，最多也就32个1，但是这时已经大于了`MAXIMUM_CAPACITY` ，所以取值到`MAXIMUM_CAPACITY` 。 

```java
	       n=     ;  1000 0000  0000 0000  0000 0000  0000 0000
	  n |= n >>> 1;  1100 0000  0000 0000  0000 0000  0000 0000  将最高位拷贝到下1位
	  n |= n >>> 2;  1111 0000  0000 0000  0000 0000  0000 0000  将上述2位拷贝到紧接着的2位
	  n |= n >>> 4;  1111 1111  0000 0000  0000 0000  0000 0000  将上述4位拷贝到紧接着的4位
	  n |= n >>> 8;  1111 1111  1111 1111  0000 0000  0000 0000  将上述8位拷贝到紧接着的8位
	  n |= n >>> 16; 1111 1111  1111 1111  1111 1111  1111 1111  将上述16位拷贝到紧接着的16位

```

由上面可以看出其通过这五次的计算，最后的结果刚好可以填满32位的空间，也就是一个int类型的空间，这就是为什么必须是int类型，且最多只无符号右移16位！

```java
  return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
```


其中的MAXIMUM_CAPACITY 是HashMap的最大空间为1 << 30，即2^30刚好一个G，所以HashMap大小不是取决于堆内存！

接下来就来讨论为什么要减一：

 以 n = 8为例
	 0000 1000
	 最后的结果为：
	 0000 1111
	 对其加一得到的是16，显然没有把自身包含进去
	 
	 若减一
	 n = 7
	 0000 0111
	 最后的结果为：
	 0000 0111
	 对其加一得到的是8

所以在一开始进行减一的操作是为了防止出现二的整数幂时，没有把自身包含进范围！

举一个例子说明下吧。 

![image-20210525211111123](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210525211132.png)

开始以为这个是个Bug，感觉应该这么写：

```java
this.threshold = tableSizeFor(initialCapacity) * this.loadFactor;
```

这样才符合threshold的意思（当HashMap的size到达threshold这个阈值时会扩容）。 
但是，请注意，在构造方法中，并没有对table这个成员变量进行初始化，table的初始化被推迟到了put方法中，在put方法中会对threshold重新计算

后面再进行put操作中会使用这个threshold 进行操作

![img](https://img2020.cnblogs.com/i-beta/804160/202003/804160-20200311102300535-731273609.png)

```java
    /**
     * HashMap允许key为null，null的hash为0（也意味着HashMap允许key为null的键值对），
     * 非null的key的hash高16位和低16位分别由由：key的hashCode
     * 高16位和hashCode的高16位异或hashCode的低16位组成。主要是为了增强hash的随机性减少hash&(n-1)的
     * 随机性，即减小hash冲突，提高HashMap的性能。所以作为HashMap的key的hashCode函数的实现对HashMap
     * 的性能影响较大，极端情况下：所有key的hashCode都相同，这是HashMap的性能很糟糕！
     */
static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
 
 
    /**
     * 在new HashMap的时候，如果我们传入了大小参数，这是HashMap会对我们传入的HashMap容量进行传到
     * tableSizeFor函数处理：这个函数主要功能是：返回一个数：这个数是大于等于cap并且是2的整数次幂
     * 的所有数中最小的那个，即返回一个最接近cap(>=cap)，并且是2的整数次幂的那个数。
     * 具体逻辑如下:一个数是2的整数次幂，那么这个数减1的二进制就是一串掩码，即二进制从某位开始是一 串连续的1。
     */
    static final int tableSizeFor(int cap) {
        //举例而言：n的第三位是1(从高位开始数)， 
        int n = cap - 1;
 
        n |= n >>> 1; 
        n |= n >>> 2; 
        n |= n >>> 4; 
        n |= n >>> 8; 
        n |= n >>> 16; 
        //举例而言：如果n为: 00010000 00000000 00000000 000
        /*
        n |= n >>> 1;->n：00011000 00000000 00000000 0000
        n |= n >>> 2;->n: 00011110 00000000 00000000 0000
        n |= n >>> 4;->n: 00011111 11100000 00000000 0000
        n |= n >>> 8;->n: 00011111 11111111 11100000 0000
        n |= n >>> 16;->n:00011111 11111111 11111111 1111
        
        返回n+1：00010000 00000000 00000000 000(>=cap并且为2的整数次幂，与cap差值最小的那个)
        最后的n+1一定是2的整数次幂，并且一定是>=cap
        整体的思路就是：如果n二进制的第k为1，那么经过上面四个‘|’运算后[0,k]位都变成了1,
        即：一连串连续的二进制‘1’(掩码)，最后n+1一定是2的整数次幂（如果不溢出）
        最后返回的时候return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;如果比最大值小，就返回运算结果+1，又正好将所有的1转换成了0，且进了一位，刚好是2^x次方
        */
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```

## 2、HashMap的put函数源码

```java
//put函数入口,两个参数：key和value
public V put(K key, V value) {
        //下面分析这个函数，注意前3个参数，后面2个参数这里不太重要，因为所有的put后面2个参数都一样
        return putVal(hash(key), key, value, false, true);
    }
 
 
 
//下面是put函数的核心处理函数
/**
     * Implements Map.put and related methods
     *
     * @param hash hash for key           
     * @param key the key               
     * @param value the value to put       
     * @param onlyIfAbsent if true, don't change existing value
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none
     */
 
    //hash：key的hashCode
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        //上面提到过HashMap是懒加载，所有put的时候要先检查table数组是否已经初始化了，
        //没有初始化得先初始化table数组，保证table数组一定初始化了
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;//这个函数后面有resize函数分析
    
        //到这里表示table数组一定初始化了
        //与上面get函数相同，指定key的Node，put在table数组的i=(n-1)&hash下标位置，get的时候
        //也是从table数组的该位置搜索
        if ((p = tab[i = (n - 1) & hash]) == null)
            //如果i位置还没有存储元素，则把当前的key，value封装为Node，存储在table[i]位置
            tab[i] = newNode(hash, key, value, null);
        else {
       //如果table[i]位置已经有元素了，则接下来执行的是：
       //首先判断链表或者二叉树中时候已经存在key的键值对，存在的话就更新它的value
       //不存在的话把当前的key，value插入到链表的末尾或者插入到红黑树中
       //如果链表或者红黑树中已经存在Node.key等于key，则e指向该Node，即
       //e指向一个Node：该Node的key属性与put时传入的key参数相等的那个Node，后面会更新e.value
            Node<K,V> e; K k;
 
       //为什么get和put先判断p.hash==hash,下面的if条件中去掉hash的比较也可以逻辑也正确？
       //因为hash的比较是两个整数的比较，比较的代价相对较小，key是泛型，对象的比较比整数比较
        //代价大，所以先比较hash，hash相等在比较key
            if (p.hash == hash &&//
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;//e指向一个Node：该Node的key属性与put时传入的key参数相等的那个Node
            else if (p instanceof TreeNode)
               //红黑树的插入操作，如果已经存在该key的TreeNode，则返回该TreeNode，否则返回null
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                //table[i]处存放的是链表，接下来和TreeNode类似
                //在遍历链表过程中先判断是key先前是否存在，如果存在则e指向该Node
                //否则将该Node插入到链表末尾，插入后判断链表长度是否>=8，是的话要进行额外操作
                
                //binCountt最后的值是链表的长度
                for (int binCount = 0; ; ++binCount) {
                    
                    if ((e = p.next) == null) {
                   //遍历到了链表最后一个元素,接下来执行链表的插入操作，先封装为Node再插入
                   //p指向的是链表最后一个节点，将待插入的Node置为p.next，就完成了单链表的插入
                        p.next = newNode(hash, key, value, null);
 
                       
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            //TREEIFY_THRESHOLD值是8， binCount>=7,然后又插入了一个新节点，            
                            //链表长度>=8，这时要么进行扩容操作，要么把链表结构转为红黑树结构
                            //我们接下会分析treeifyBin的源码实现
                            treeifyBin(tab, hash);
                        break;
                    }
                    
                    //当p不是指向链表末尾的时候：先判断p.key是否等于key，等于的话表示当前key
                    //已经存在了，令e指向p，停止遍历，最后会更新e的value；
                    //不等的话准备下次遍历，令p=p.next，即p=e
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
 
            
            if (e != null) { // existing mapping for key
                //表示当前的key之前已经存在了，并且上面的逻辑保证:e.key一定等于key
                //这是更新e.value就好
                V oldValue = e.value;//保存oldvalue
                
                //onlyIfAbsent默是false，evict为true
                //onlyIfAbsent为true表示如果之前已经存在key这个键值对了，那么后面在put这个key 
                //时，忽略这个操作，不更新先前的value，这里连接就好 
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;//更新e.value
                
                //这个函数的默认实现是“空”，即这个函数默认什么操作都不执行，那为什么要有它呢？
                //这是个hook/钩子函数，主要要在LinkedHashMap中，LinkedHashMap重写了这个函数
                //后面讲解LinkedHashMap时会详细讲解
                afterNodeAccess(e);
                return oldValue;//返回旧的value
            }
        }
 
        //如果是第一次插入key这个键，就会执行到这里
        ++modCount;//failFast机制
        
        //size保存的是当前HashMap中保存了多少个键值对，HashMap的size方法就是直接返回size
        //之前说过，threshold保存的是当前table数组长度*loadfactor，如果table数组中存储的
        //Node数量大于threshold，这时候会进行扩容，即将table数组的容量翻倍。后面会详细讲解
        //resize方法
        if (++size > threshold)
            resize();
        
        //这也是一个hook函数，作用和afterNodeAccess一样
        afterNodeInsertion(evict);
        return null;
    }
 
    
    //将链表转换为红黑树结构，在链表的插入操作后调用
/**
     * Replaces all linked nodes in bin at index for given hash unless
     * table is too small, in which case resizes instead.
     */
    final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
        
        //MIN_TREEIFY_CAPACITY值是64,也就是当链表长度>8的时候，有两种情况：
        //如果table数组的长度<64,此时进行扩容操作
        //如果table数组的长度>64，此时进行链表转红黑树结构的操作
        //具体转细节在面试中几乎没有问的，这里不细讲了，
        //大部同学认为链表长度>8一定会转换成红黑树，这是不对的！！！
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            do {
                TreeNode<K,V> p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }
```

## 3、HashMap的resize函数源码分析

重点中的重点，面试谈到HashMap必考resize相关知识

```java
/**
     *    有两种情况会调用当前函数： 
     *    1.之前说过HashMap是懒加载，第一次hHashMap的put方法的时候table还没初始化，
     * 这个时候会执行resize，进行table数组的初始化，table数组的初始容量保存在threshold中（如果从构造器
     * 中传入的一个初始容量的话），如果创建HashMap的时候没有指定容量，那么table数组的初始容
     * 量是默认值：16。即，初始化table数组的时候会执行resize函数
     *    2.扩容的时候会执行resize函数，当size的值>threshold的时候会触发扩容，即执行resize方法，
     * 这时table数组的大小会翻倍。
     * 
     *   注意我们每次扩容之后容量都是翻倍（*2），所以HashMap的容量一定是2的整数次幂，那么HashMap的
     * 容量为什么一定得是2的整数次幂呢？（面试重点） 要知道原因，首先回顾我们put
     * key的时候，每一个key会对应到一个桶里面，桶的索引是这样计算的： index = hash & (n-1)，
     * index的计算最为直观的想法是：hash%n，即通过取余的方式把当前的key、value键值对散列到各个桶中；
     * 那么这里为什么不用取余(%)的方式呢？原因是CPU对位运算支持较好，即位运算速度很快。
     *   另外,当n是2的整数次幂时：hash&(n-1)与hash%(n-1)是等价的，但是两者效率来讲是不同的，位运算的效率
     * 远高于%运算。基于这一点，HashMap中使用的是hash&(n-1)。这还带来了一个好处，就是将旧数组中的Node迁移到扩容后
     * 的新数组中的时候有一个很方便的特性：HashMap使用table数组保存Node节点，所以table数组扩容的时候（数组扩容）一
     * 定得是先重新开辟一个数组，然后把就数组中的元素重新散列到新数组中去。这里举一个例子来来说明这个特性：下面以Hash初始容量
     * n=16，默认loadfactor=0.75举例（其他2的整数次幂的容量也是类似的）：默认容量：n=16，二进制：10000；n-1：15,
     * n-1二进制：01111，即一连串1。某个时刻，map中元素大于16*0.75=12，即size>12，此时我们新建了一个数组，
     * 容量为扩容前的两倍，newtab，len=32;接下来我们需要把table中的Node搬移(rehash)到newtab。从table的i=0
     * 位置开始处理,假设我们当前要处理table数组i索引位置的node，那这个node应该放在newtab的那个位置呢？下面的hash表
     * 示node.key对应的hash值，也就等于node.hash属性值,另外为了简单，下面的hash只写出了8位（省略的高位的0），实际上
     * hash是32位：node在newtab中的索引：index=hash%len=hash&(len-1)=hash&(32-1)=hash&31
     * =hash&(0x0001_1111)；再看node在table数组中的索引计算：i=hash&(16-1)=hash&15
     * =hash&(0x0000_1111)。注意观察两者的异同：i=hash&(0x0000_1111);index=hash&(0x0001_1111)
     * 这个表达式有个特点：index=hash&(0x0001_1111)=hash&(0x0000_1111) |
     * hash&(0x0001_0000) =hash&(0x0000_1111) | hash&n)=i+( hash&n)。什么意思呢：
     * hash&n要么等于n要么等于0;也就是：inde要么等于i，要么等于i+n;再具体一点：当hash&n==0的时候，index=i;
     * 当hash&n==n的时候，index=i+n;这有什么用呢？当我们把table[i]位置的所有Node迁移到newtab中去的时候：
     * 这里面的node要么在newtab的i位置（不变），要么在newtab的i+n位置；也就是我们可以这样处理：把table[i]这个桶中的
     * node拆分为两个链表l1和类：如果hash&n==0，那么当前这个node被连接到l1链表；否则连接到l2链表。这样下来，
     * 当遍历完table[i]处的所有node的时候，我们得到两个链表l1和l2，这时我们令newtab[i]=l1,newtab[i+n]=l2,
     * 这就完成了table[i]位置所有node的迁移/rehash，这也是HashMap中容量一定的是2的整数次幂带来的方便之处。
     * 下面的resize的逻辑就是上面讲的那样。将table[i]处的Node拆分为两个链表，这两个链表再放到newtab[i]
     * 和newtab[i+n]位置
    
     * Initializes or doubles table size.  If null, allocates in
     * accord with initial capacity target held in field threshold.
     * Otherwise, because we are using power-of-two expansion, the
     * elements from each bin must either stay at same index, or move
     * with a power of two offset in the new table.
     *
     * @return the table
     */
    final Node<K,V>[] resize() {
        //oldTab 表示的是扩容之前的哈希表
        Node<K,V>[] oldTab = table;
        //oldCap 表示的是扩容之前的数组长度,如果扩容前的数组为空，设置旧的数组长度为0，否则设置为旧哈希表长度
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        //pldThr 表示的是扩容之前数组的扩容阈值
        int oldThr = threshold;
        //newCap 表示的是新的数组长度，newThr 表示的是新的扩容阈值
        int newCap, newThr = 0;
        //当扩容前的数组长度大于0时，即此时数组正常初始化，里面存有数据
        if (oldCap > 0) {
            //当扩容前的数组大度大于系统支持的最大值时
            if (oldCap >= MAXIMUM_CAPACITY) {
                //设置扩容阈值为int最大值
                threshold = Integer.MAX_VALUE;
                //此时无法扩容，返回扩容前的哈希表
                return oldTab;
            }
            //此时数组长度在系统支持的范围内，设置新的数组长度为旧的数组长度的两倍，并且比较是否小于系统支持的最大值
            //与旧的数组长度是否大于等于16
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)
                //满足上述两个条件时，新的扩容阈值增加为旧的扩容阈值的两倍
                newThr = oldThr << 1; // double threshold
        }
        //数组长度=0的情况，即哈希表未初始化，且旧的扩容阈值大于0
        //有以下几种情况：new HashMap(initCap,loadFactor),new HashMap(initCap),new HashMap(map)
        else if (oldThr > 0) // initial capacity was placed in threshold
            //设置新的数组长度为旧的数组扩容阈值
            newCap = oldThr;
        //oldCap==0且oldThr==0的情况
        else {               // zero initial threshold signifies using defaults
            //设置新的数组长度为默认值
            newCap = DEFAULT_INITIAL_CAPACITY;
            //使用负载因子计算新的扩容阈值
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
        //如果新的扩容阈值等于0时，即旧的数组长度大于0，但不满足上述两种条件，导致newThr没有赋值
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        //设置扩容阈值为新的扩容阈值
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
                //构造扩容后的哈希表对象
            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        //设置table为新的哈希表
        table = newTab;
        //旧的哈希表不为空。即里面有数据
        if (oldTab != null) {
            //遍历数组
            for (int j = 0; j < oldCap; ++j) {
                Node<K,V> e;
                if ((e = oldTab[j]) != null) {
                    //对象引用设为空，方便JVM回收
                    oldTab[j] = null;
                    //①这里表示数组中这个位置只有单个元素，不是链表
                    if (e.next == null)
                        //使用哈希寻址算法放入新哈希表中
                        newTab[e.hash & (newCap - 1)] = e;
                    //②此时这个元素是红黑树结构
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                    else { // preserve order
                        //③链表结构
                        //loHead表示低位链表的头结点，loTail表示低位链表的尾节点
                        //hiHead表示高位链表的头结点，hiTail表示高位链表的尾节点
                        Node<K,V> loHead = null, loTail = null;
                        Node<K,V> hiHead = null, hiTail = null;
                        //链表的下一个指针
                        Node<K,V> next;
                        //循环遍历链表
                        do {
                            //指向下一个节点
                            next = e.next;
                            //判断是否是低位链表
                            if ((e.hash & oldCap) == 0) {
                                //尾节点是否为空
                                if (loTail == null)
                                    //头结点指向e
                                    loHead = e;
                                else
                                    //尾节点下一个指向e
                                    loTail.next = e;
                                loTail = e;
                            }
                            else {
                                //判断高位尾部是否为空
                                if (hiTail == null)
                                    //头结点指向e
                                    hiHead = e;
                                else
                                    //尾节点下一位指向e
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);

                        //判断低位尾节点是否为空
                        if (loTail != null) {
                            //置为空，因为有可能存在其他引用
                            loTail.next = null;
                            //把头结点放入数组对应下标的位置，低位放在旧数组一样下标的位置，因为每次遍历旧
                            //数组，得到的节点在新的数组要不是之前的位置，要不就是之前的位置+旧数组长度
                            //不可能旧数组不同位置的位置的链表在新的数组中会在一个位置，所以不用担心新位置的
                            //链表覆盖的问题
                            newTab[j] = loHead;
                        }
                        //判断高位尾节点是否为空
                        if (hiTail != null) {
                            //置为空，因为有可能存在其他引用
                            hiTail.next = null;
                            //把头结点放入数组对应下标的位置，高位放在旧数组下标+旧数组长度的位置
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }

```

### 3.1 判别低位链表和高位链表

> 使用e.hash & oldCap==0 表示是低位链表，否则就是高位链表。
>
> 分析：
>
> 什么是高位和低位链表？
>
> 以下面这张图为例，未扩容的数组长度为16，扩容后的数组长度为32。在未扩容前的哈希表的下标为15的位置中，由hash&（n-1）得出1111（即下标15的二进制），因此，在下标15位置上的链表的元素的hash值后四位一定是1111。不可能出现0位
>
> 那么就会出现两种情况，
>
> 1111 前面一位是1 即hash值为 …1 1111
>
> 1111 前面一位是0 即hash值为 …0 1111
>
> 根据前面一位是1或者0判断链表元素是高位还是低位，从而存放到指定的值。
>
> 知道了什么是高位和低位链表，根据e.hash & oldCap==0 就可以判断出是高位还是低位链表，这个又是怎么判断的？
>
> oldCap表示的是扩容前的数组长度，这里oldCap=16=1 0000
>
> e.hash&oldCap有以下两种情况
>
> ​    1 1111
>  &1 0000
>
>  = 1 0000 高位是1，存入高链，然后再计算在新链表中的位置，是**1 1111 &（32-1）= 1 1111 & 1 1111  
>
> 对比旧的位置 1 1111 &（16-1）=1 1111 & 1111 高位多了一个1，2^4=16,所以是原来位置加上旧数组的长度
>
> 0 1111
>  & 1 0000
>
>  = 0 0000 高位是0，存入低链。

![img](https://img-blog.csdnimg.cn/img_convert/39549439ae423153151e4a2d151db5dc.png)



### 3.2 节点重 hash 为什么只可能分布在 “原索引位置” 与 “原索引 + oldCap 位置” ？

![image-20210527181125675](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210527181226.png)

### JDK 1.8扩容过程

JDK1.8 普通链表的扩容代码，如下图所示，在上文已经分析过了：主要是在一个 do/while 中处理同一个位置的所有节点。

![img](https://img-blog.csdnimg.cn/20190825154241486.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3YxMjM0MTE3Mzk=,size_16,color_FFFFFF,t_70)

![image-20210527182218691](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210527182220.png)



### 3.3  死循环问题

> 在 JDK 1.8 以前，Java 语言在并发情况下使用 HashMap 造成 Race Condition，从而导致死循环。程序经常占了 100% 的 CPU，查看堆栈，你会发现程序都 Hang 在了 “HashMap.get()” 这个方法上了，重启程序后问题消失。具体分析可以查看这篇文章：疫苗：JAVA HASHMAP的死循环，有人将这个问题当成一个 bug 提给了 Sun，但是 Sun 认为这并不是个 bug，因为HashMap 本来就不保证并发的线程安全性，在并发下，要用 ConcurrentHashMap 来代替。
>
> 那么，在JDK 1.8 的时候，这个问题解决了吗？
>
> 我们知道，JDK 1.8 以前，导致死循环的主要原因是扩容后，节点的顺序会反掉，如下图：扩容前节点 A 在节点 C 前面，而扩容后节点 C 在节点 A 前面。

![img](https://img-blog.csdn.net/20180203174605773?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdjEyMzQxMTczOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

假设现在有两个线程A、B同时对下面这个HashMap进行扩容操作：

正常扩容后的结果是下面这样的：

![img](https://zhy-myblog.oss-cn-shenzhen.aliyuncs.com/public/blogArticles/2019-03-30/1553942282.jpeg)

但是当线程A执行到上面transfer函数的第11行代码时，CPU时间片耗尽，线程A被挂起。即如下图中位置所示：

![img](https://zhy-myblog.oss-cn-shenzhen.aliyuncs.com/public/blogArticles/2019-03-30/1553942674.png)



此时线程A中：e=3、next=7、e.next=null

![img](https://zhy-myblog.oss-cn-shenzhen.aliyuncs.com/public/blogArticles/2019-03-30/1553943048.jpeg)

当线程A的时间片耗尽后，CPU开始执行线程B，并在线程B中成功的完成了数据迁移

![img](https://zhy-myblog.oss-cn-shenzhen.aliyuncs.com/public/blogArticles/2019-03-30/1553943250.jpeg)

重点来了，根据Java内存模式可知，线程B执行完数据迁移后，此时主内存中newTable和table都是最新的，也就是说：7.next=3、3.next=null。

随后线程A获得CPU时间片继续执行newTable[i] = e，将3放入新数组对应的位置，执行完此轮循环后线程A的情况如下：

![img](https://zhy-myblog.oss-cn-shenzhen.aliyuncs.com/public/blogArticles/2019-03-30/1553943714.jpeg)

接着继续执行下一轮循环，此时e=7，从主内存中读取e.next时发现主内存中7.next=3，于是乎next=3，并将7采用头插法的方式放入新数组中，并继续执行完此轮循环，结果如下：

![img](https://zhy-myblog.oss-cn-shenzhen.aliyuncs.com/public/blogArticles/2019-03-30/1553944363.jpeg)

执行下一次循环可以发现，next=e.next=null，所以此轮循环将会是最后一轮循环。接下来当执行完e.next=newTable[i]即3.next=7后，3和7之间就相互连接了，当执行完newTable[i]=e后，3被头插法重新插入到链表中，执行结果如下图所示：

![img](https://zhy-myblog.oss-cn-shenzhen.aliyuncs.com/public/blogArticles/2019-03-30/1553944998.jpeg)

上面说了此时e.next=null即next=null，当执行完e=null后，将不会进行下一轮循环。到此线程A、B的扩容操作完成，很明显当线程A执行完后，HashMap中出现了环形结构，当在以后对该HashMap进行操作时会出现死循环。

并且从上图可以发现，元素5在扩容期间被莫名的丢失了，这就发生了数据丢失的问题

##### 解释2 

###### 头插法

https://segmentfault.com/a/1190000024510131

我们把目光聚焦到这几行代码：

```java
 //获取下一个元素，记录到一个临时变量，以便后面使用
 Entry<K,V> next = e.next;
 // 计算节点在新数组中的下标
 int i = indexFor(e.hash, newCapacity);
 // 将旧节点插入到新节点的头部
 e.next = newTable[i];
 //这行才是真正把数据插入新数组中，前面那行代码只是设置当前节点的next
 newTable[i] = e;
 //将下一个元素赋值给当前元素，以便遍历下一个元素
 e = next;
```

假设刚开始hashMap有这些数据

![img](https://segmentfault.com/img/remote/1460000024510134)



调用put方法需要进行一次扩容，刚开始会创建一个空的数组，大小是以前的2倍，如图所示：

![img](https://segmentfault.com/img/remote/1460000024510136)



开始第一轮循环：

```java
 //next= 7   e = 3  e.next = 7
 Entry<K,V> next = e.next;
 // i=3
 int i = indexFor(e.hash, newCapacity);
 //e.next = null ，刚初始化时新数组的元素为null
 e.next = newTable[i];
 //给新数组i位置 赋值 3
 newTable[i] = e;
 // e = 7
 e = next;
```

执行完之后，第一轮循环之后数据变成这样的

![image.png](https://segmentfault.com/img/bVbO1bJ)



再接着开始第二轮循环：

```java
 //next= 5   e = 7  e.next = 5
 Entry<K,V> next = e.next;
 // i=3
 int i = indexFor(e.hash, newCapacity);
 //e.next = 3 ，此时相同位置上已经有key=3的值了，将该值赋值给当前元素的next
 e.next = newTable[i];
 //给新数组i位置 赋值 7
 newTable[i] = e;
 // e = 5
 e = next;
```

上面会构成一个新链表，连接的顺序正好反过来了。

![image.png](https://segmentfault.com/img/bVbO1bK)

由于第二次循环时，节点key=7的元素插到相同位置上已有元素key=3的前面，所以说是采用的头插法。



###### 死循环的产生

接下来重点看看死循环是如何产生的？

假设数据跟元素数据一致，有两个线程：线程1 和 线程2，同时执行put方法，最后同时调用transfer方法。

线程1 先执行，到 Entry<K,V> next = e.next; 这一行，被挂起了。

```java
 //next= 7   e = 3  e.next = 7，注意这个时候保留了原始的节点顺序，3的后面一个是7，但是其实被线程2扩容后
//3的后面一个已经变成null，这里已经是旧数据了
 Entry<K,V> next = e.next;
 int i = indexFor(e.hash, newCapacity);
 e.next = newTable[i];
 newTable[i] = e;
 e = next;
```

此时线程1 创建的数组会创建一个空数组

![img](https://segmentfault.com/img/remote/1460000024510137)

接下来，线程2开始执行，由于线程2运气比较好，没有被中断过，执行完毕了。

![img](https://segmentfault.com/img/remote/1460000024510138)

过一会儿，线程1被恢复了，重新执行代码。

```java
 //next= 7   e = 3  e.next = 7
 Entry<K,V> next = e.next;
 // i = 3
 int i = indexFor(e.hash, newCapacity);
 // e.next = null，刚初始化时新数组的元素为null
 e.next = newTable[i];
 // 给新数组i位置 赋值 3
 newTable[i] = e;
 // e = 7
 e = next;
```

这时候线程1的数组会变成这样的

![image.png](https://segmentfault.com/img/bVbO1bL)

再执行第二轮循环，此时的e=7

```java
 //next= 3   e = 7  e.next = 3，到了这里，取7的next又是取到最新扩容后的节点
 Entry<K,V> next = e.next;
 // i = 3
 int i = indexFor(e.hash, newCapacity);
 // e.next = 3，此时相同位置上已经有key=3的值了，将该值赋值给当前元素的next
 e.next = newTable[i];
 // 给新数组i位置 赋值 7
 newTable[i] = e;
 // e = 3
 e = next;
```

这里特别要说明的是 此时e=7，而e.next为什么是3呢？

因为hashMap的数据是公共的，还记得线程2中的生成的数据吗？

![image.png](https://segmentfault.com/img/bVbO1bU)

此时e=7，那么e.next肯定是3。

经过上面第二轮循环之后，线程1得到的数据如下：

![img](https://segmentfault.com/img/remote/1460000024510139)

此时由于循环判断还没有退出，判断条件是： while(null != e)，所以要开始第三轮循环：

```java
 //next= null   e = 3  e.next = null
 Entry<K,V> next = e.next;
 // i = 3
 int i = indexFor(e.hash, newCapacity);
 // e.next = 7，关键的一步，由于第二次循环是 key:7 .next = key:3，现在key:3.next = key:7
 e.next = newTable[i];
 // 给新数组i位置 赋值 3
 newTable[i] = e;
 // e = null
 e = next;
```

由于e=null，此时会退出循环，最终线程1的数据会是这种结构：

![image.png](https://segmentfault.com/img/bVbO1bW)

key:3 和 key:7又恢复了刚开始的顺序，但是他们的next会相互引用，构成环形引用。

注意，此时调用hashmap的get方法获取数据时，如果只是获取循环链上key:3 和 key:7的数据，是不会有问题的，因为可以找到。就怕获取循环链上没有的数据，比如：key:11，key:15等，会进入无限循环中导致CPU使用率飙升。







### 3.4 线程不安全

#### 3.4.1 数据覆盖问题

根据上面JDK1.7出现的问题，在JDK1.8中已经得到了很好的解决，如果你去阅读1.8的源码会发现找不到transfer函数，因为JDK1.8直接在resize函数中完成了数据迁移。另外说一句，JDK1.8在进行元素插入时使用的是尾插法。

为什么说JDK1.8会出现数据覆盖的情况喃，我们来看一下下面这段JDK1.8中的put操作代码：

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
    // 步骤②：计算index，并对null做处理 
        if ((p = tab[i = (n - 1) & hash]) == null) // 如果没有hash碰撞则直接插入元素
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }

```

> 其中第六行代码步骤2是判断是否**出现hash碰撞**，假设两个线程A、B都在进行put操作，并且hash函数计算出的插入下标是相同的，当线程A执行完第六行代码后由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，然后线程A获得时间片，由于之前已经进行了hash碰撞的判断，所有此时不会再进行判断，而是直接进行插入，这就导致了线程B插入的数据被线程A覆盖了，从而线程不安全。
>
> 除此之前，还有就是代码的第38行处有个**++size**，我们这样想，还是线程A、B，这两个线程同时进行put操作时，假设当前HashMap的zise大小为10，当线程A执行到第38行代码时，从主内存中获得size的值为10后准备进行+1操作，但是由于时间片耗尽只好让出CPU，线程B快乐的拿到CPU还是从主内存中拿到size的值10进行+1操作，完成了put操作并将size=11写回主内存，然后线程A再次拿到CPU并继续执行(此时size的值仍为10)，当执行完put操作后，还是将size=11写回内存，此时，线程A、B都执行了一次put操作，但是size的值只增加了1，所有说还是由于数据覆盖又导致了线程不安全。

> `HashMap`的线程不安全主要体现在下面两个方面：
> 1.在JDK1.7中，当并发执行扩容操作时会造成环形链和数据丢失的情况。
> 2.在JDK1.8中，在并发执行put操作时会发生数据覆盖的情况。

## 4、indexFor

###  4.1  (n - 1) & hash与取模运算

![image-20210527190834748](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210527190836.png)

## 5、hash函数算法

```java
static final int hash(Object key) {
   int h;
   return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}


```

此时我们心中会有两个疑惑：

- 为什么要无符号右移 16 位后做异或运算
- key 本身的 hashCode 直接拿来用不行吗

来看这样一个例子：



![img](https://user-gold-cdn.xitu.io/2020/6/26/172ef468f2450022?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



将 h 无符号右移 16 为相当于将高区 16 位移动到了低区的 16 位，再与原 hashcode 做异或运算，可以看作是`将高低位二进制特征混合起来`。

从上图中可以看出，高位的 16 位与原 hashcode 相比没有发生变化，低位的 16 位发生了变化。

上面的 (h = key.hashCode ()) ^ (h >>> 16) 进行运算后，可以把高区与低区的二进制特征混合到低区，那么为什么要这么做呢？

我们要知道，上面计算出来的hashcode值接下来要参与到hashmap中数组槽位的计算，其计算公式是：(n - 1) & hash，现在假设数组槽位大小是16，那么槽位计算过程如下：



![img](https://user-gold-cdn.xitu.io/2020/6/26/172ef46e16d6f023?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



观察可以看出，如果我们不做刚才移位异或运算，那么在计算槽位时将丢失高区特征。也许你可能会说，即使丢失了高区特征，不同 hashcode 也可以计算出不同的槽位来，但是细想当两个哈希码很接近时，那么这高区的一点点差异就可能导致一次哈希碰撞，所以这也是将性能做到极致的一种体现。

### 为什么要采用异或运算

异或运算能更好的保留各部分的特征，如果采用 & 运算计算出来的值会向 1 靠拢，采用 | 运算计算出来的值会向 0 靠拢。

## 6、红黑树

> 红黑树详解---彻底搞懂红黑树
>
> https://blog.csdn.net/inspiredbh/article/details/60474958
>
> 红黑树的理解与Java实现
>
> https://blog.csdn.net/weixin_42786274/article/details/86557922
>
> 详解红黑树（图）
>
> https://luozy.net/blog/archives/%E8%AF%A6%E8%A7%A3%E7%BA%A2%E9%BB%91%E6%A0%91%E5%9B%BE
>
> 一篇文章彻底搞懂红黑树(多图,看完包懂)
>
> https://blog.csdn.net/vjhghjghj/article/details/88779703?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&spm=1001.2101.3001.4242

### [树的高度与深度](https://www.cnblogs.com/jianglinliu/p/11197715.html)

树中的深度、高度及层数相关概念

深度是从上往下数的，高度是从下往上数的，深度和高度都涉及到节点的层数(经过学习发现，**深度、高度概念在不同的教材中有不同的定义，主要看高度深度的初值为几，有的为0，有的为1**)。

(1).**定义一（初值为0）**：节点的深度是根节点到这个节点所经历的边的个数

　　　　　　　　　　　节点的高度是该节点到叶子节点的最长路径（边数）

　　　　　　　　　　　树的高度等于根节点的高度

具体如下图所示（参考1）：

![img](https://img2018.cnblogs.com/blog/1523448/201907/1523448-20190716212515612-1703079491.png)

 

(2).**定义二(初值为1)**：节点的深度是根节点到这个节点的最长路径上的节点数

　　　　　　　　　　节点的高度是该节点到最远叶子节点的最长路径上的节点数

具体如下图所示（参考2）：

![img](https://img2018.cnblogs.com/blog/1523448/201907/1523448-20190716213737122-1273077063.png)

 

此外还有最小深度的概念。**最小深度是从根节点到最近叶子节点的最短路径上的节点数量(初值为1)**。



### 6.0 性质

> 1.根节点为黑色
>
> 2.节点为红色或者黑色
>
> 3.每个叶子节点NIL为黑色
>
> 4.节点为红色，则两个孩子都为黑色(即每条路径上不能有连续两个红色)
>
> 5.**任意一个节点**到其所有子孙节点的NIL的路径上包含相同数目的黑色节点
>
> **注意是任一个节点出发**，所以每个子树都得满足第五性质
>
>  首先解读一下规则，除了字面上看到的意思，还隐藏了哪些意思呢？
>
> **①从根节点到叶子节点的最长路径不大于最短路径的 2 倍**
>
> 怎么样的路径算最短路径？从规则 5 中，我们知道从根节点到每个叶子节点的黑色节点数量是一样的，那么纯由黑色节点组成的路径就是最短路径。
>
> 什么样的路径算是最长路径？根据规则 4 和规则 3，若有红色节点，则必然有一个连接的黑色节点，当红色节点和黑色节点数量相同时，就是最长路径，也就是黑色节点（或红色节点）*2。
>
> **②为什么说新加入到红黑树中的节点为红色节点**
>
> 从规则 4 中知道，当前红黑树中从根节点到每个叶子节点的黑色节点数量是一样的，此时假如新的是黑色节点的话，必然破坏规则。
>
> 但加入红色节点却不一定，除非其父节点就是红色节点，因此加入红色节点，破坏规则的可能性小一些，下面我们也会举例来说明。
>
> **什么情况下，红黑树的结构会被破坏呢？**破坏后又怎么维持平衡，**维持平衡主要通过两种方式【变色】和【旋转】，【旋转】又分【左旋】和【右旋】**，两种方式可相互结合。 
>
> 红黑树，通过对任何一条从根到叶子的简单路径上各个节点的颜色进行约束，红黑树可以保证没有一条路径会比其他路径长出2倍以上，所以称之为**平衡**。
>
>   对于上面的第5点，又有一个新的定义，**黑高**：从某个节点x出发(不含该节点)到达一个叶结点的任意一条简单路径上的黑色节点个数称之为该节点的**黑高**，**注意黑高是将nil计算在内的**。
>
> 
>
>   **将上图的黑高标识出来：**
>
> ![img](https://img-blog.csdn.net/20150113181500093?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3lwMzMxMjAz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

>   红黑树是一颗二叉查找树，所不同的是，它的每个节点上增加了一个存储位来表示节点的颜色，可以是RED或BLACK。红黑树的每个节点包含5个属性：color、key、left、right、和p(父节点)。如果一个节点没有子节点或父节点，在二叉查找树中，相应的指针就会指向NULL(空)，而这里就是红黑树与二叉查找树的第二个不同之处：
>
>  红黑树中并没有任何一个节点的左子节点、右子节点或者父节点会指向NULL(空)，取而代之的是使用一个**nil**的哨兵节点来放在原来为NULL的位置，类似于[【算法导论】10.2不带哨兵节点和带哨兵节点的双向链表](http://blog.csdn.net/cyp331203/article/details/42388065)文中带哨兵节点的双向链表。在红黑树中，哨兵节点**nil**是所有一个与树种普通节点有相同属性的对象。**它的color属性为BLACK**，而它的其他属性可以任意设置，一般时没有什么意义。nil用来替换二叉查找树中原本为NULL的指针的指向，同时root节点的父指针指向nil。我们将除nil节点的其他节点视为内部节点，在红黑树中，我们主要关注内部节点。
>
> **红黑树结构图：**

![img](https://img-blog.csdn.net/20150113181507448?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3lwMzMxMjAz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



#### 6.0.1  ***红黑树的单分支情况***

##### 1、可能出现的单分支：

![img](https://img-blog.csdn.net/20150113205350656?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3lwMzMxMjAz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



>   因为只有在上面的两种情况下才有可能在单分支的情况下，保持上面的第五条性质(注意nil节点要计算在内，最后的节点都是指向nil节点的)。而下面的几种情况，都是不能保证第五条性质的单分支情况。

#####   2、不可能出现的单分支情况：

![img](https://img-blog.csdn.net/20150113205906525?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3lwMzMxMjAz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

> 因为上述四中但分支情况下，不能保证性质5。例如前两种，必定会让红色节点->叶子节点(nil)线路的黑色节点数比红色节点->黑色节点线路的黑色节点数少一。上面黑色节点是公共父节点，所以加上nil节点是一样的，但是这里左边明显多了一个nil节点了，所以，我们容易发现，**红黑树种只可能有双分支或黑上红下的单分支情况**。



### 6.1 左旋代码

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181227152700744.gif)

```java
上面对左旋的概念已经有了感性的认识了，这里就不再赘述了，我们从下面的代码中结合上面的示意图，探讨一下左旋的具体实现：
 
/*************对红黑树节点x进行左旋操作 ******************/
/*
 * 左旋示意图：对节点x进行左旋
 *     p                       p
 *    /                       /
 *   x                       y
 *  / \                     / \
 * lx  y      ----->       x  ry
 *    / \                 / \
 *   ly ry               lx ly
 * 左旋做了三件事：
 * 1. 将y的左子节点赋给x的右子节点,并将x赋给y左子节点的父节点(y左子节点非空时)
 * 2. 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右)
 * 3. 将y的左子节点设为x，将x的父节点设为y
 */
private void leftRotate(RBNode<T> x) {
    //1. 将y的左子节点赋给x的右子节点，并将x赋给y左子节点的父节点(y左子节点非空时)
    RBNode<T> y = x.right;
    x.right = y.left;
    
    if(y.left != null) 
        y.left.parent = x;
    
    //2. 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右)
    y.parent = x.parent;
    
    if(x.parent == null) {
        this.root = y; //如果x的父节点为空，则将y设为父节点
    } else {
        if(x == x.parent.left) //如果x是左子节点
            x.parent.left = y; //则也将y设为左子节点
        else
            x.parent.right = y;//否则将y设为右子节点
    }
    
    //3. 将y的左子节点设为x，将x的父节点设为y
    y.left = x;
    x.parent = y;        
}
```

### 6.2 右旋代码

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181227152546502.gif)

```java
上面对右旋的概念已经有了感性的认识了，这里也不再赘述了，我们从下面的代码中结合上面的示意图，探讨一下右旋的具体实现：
 
/*************对红黑树节点y进行右旋操作 ******************/
/*
 * 左旋示意图：对节点y进行右旋
 *        p                   p
 *       /                   /
 *      y                   x
 *     / \                 / \
 *    x  ry   ----->      lx  y
 *   / \                     / \
 * lx  rx                   rx ry
 * 右旋做了三件事：
 * 1. 将x的右子节点赋给y的左子节点,并将y赋给x右子节点的父节点(x右子节点非空时)
 * 2. 将y的父节点p(非空时)赋给x的父节点，同时更新p的子节点为x(左或右)
 * 3. 将x的右子节点设为y，将y的父节点设为x
 */
private void rightRotate(RBNode<T> y) {
    //1. 将y的左子节点赋给x的右子节点，并将x赋给y左子节点的父节点(y左子节点非空时)
    RBNode<T> x = y.left;
    y.left = x.right;
    
    if(x.right != null) 
        x.right.parent = y;
    
    //2. 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右)
    x.parent = y.parent;
    
    if(y.parent == null) {
        this.root = x; //如果x的父节点为空，则将y设为父节点
    } else {
        if(y == y.parent.right) //如果x是左子节点
            y.parent.right = x; //则也将y设为左子节点
        else
            y.parent.left = x;//否则将y设为右子节点
    }
    
    //3. 将y的左子节点设为x，将x的父节点设为y
    x.right = y;
    y.parent = x;        
}
 
```

### 6.3 插入节点

#### 插入要点

> 首先以二叉查找树的插入方式插入新的节点(插入的节点都是叶子节点处)，并将其涂为红色。然后再进行调整使其满足红黑树的五个性质。
> 新插入节点先涂为红色的原因：因为插入一个红色节点比插入一个黑色节点违背的性质要 少，这就会减少我们调整二叉树的次数。如果插入黑色节点 ，则必然会违反第5条性质，原本平衡的红黑树因为一个路径多了一个黑色节点而肯定会失衡；如果插入为红色节点，则只有一半的机会违反第4条性质，如果父节点是黑色节点就直接不用调整了，而且违反第4条性质比违反第5条性质比较起来，前者修正要方便一线。
>
> **下图为示例图：**
>
> **N为新插入节点**
>
> **P为插入节点的父亲节点**
>
> **U为插入节点的叔父节点**
>
> **R为根节点**
>
> **G为祖先节点**
>
> 

![img](https://img-blog.csdn.net/20170305205549537)

插入后实现自平衡

建议新添加的结点默认为红色，因此这样能够让红黑树的性质尽快满足。不过如果添加的结点是根结点，设为黑色即可。

总结一下红黑树插入可能出现的所有场景：

![图片.png](https://myblog-1252088789.cos.ap-chengdu.myqcloud.com/blog/%E5%9B%BE%E7%89%87_1585705276187.png)

#### 代码

```java
    public void insertFixUp(RBNode<T> node) {
        RBNode<T> parent, gparent;//定义父节点和祖父节点
//        需要修正的条件是：父节点存在 且父节点是红色
        while (((parent = parentOf(node)) != null) && isRed(parent)) {
            gparent = parentOf(parent);//获得祖父节点
//            若父节点在祖父节点的左子节点，
            if (parent == gparent.left) {
                RBNode<T> uncle = gparent.right;//获得叔叔节点
//                 case 1 叔叔节点也是红色
                if (uncle != null && isRed(uncle)) {
                    setBlack(parent);//把父节点和叔叔节点涂成红色
                    setBlack(gparent);
                    setRed(gparent);//把祖父节点涂成红色
                    node = gparent;//把位置放到祖父节点处
                    continue;//继续while循环，重新判断
                }
//                case 2 叔叔节点是黑色 且当前节点是右子节点
                if (node == parent.right) {
                    leftRotate(parent);//从父节点处左旋
                    RBNode<T> tmp = parent;//然后将自己和父节点调换位置  和图中说的 为右旋做准备
                    parent = node;
                    node = tmp;
                }
//                case 3 叔叔节点是黑色 且当前是左子节点
                setBlack(parent);//将父节点图成黑色
                setRed(gparent);//将祖父节点涂成红色
                rightRotate(gparent);//右旋

            } else {// 若父节点在祖父节点的右子节点，与上面的情况相反 但是本质是一样
                RBNode<T> uncle = gparent.left;//获得叔叔节点
//case 1 叔叔节点也是红色
                if (uncle != null && isRed(uncle)) {
                    setBlack(parent);//将父节点涂成黑色
                    setBlack(uncle);//将叔叔节点涂成黑色
                    setRed(gparent);//将祖父节点涂成红色
                    node = gparent;//将位置放到祖父节点 继续循环判断
                    continue;
                }
//                case 2 叔叔节点是黑色的 且当前是左子节点
                if (node == parent.left) {
                    rightRotate(parent);//从父节点开始右旋
                    RBNode<T> tmp = parent;//然后就和开始一样 将父节点看成当前节点，将当前节点看成父节点 为左旋做准备
                    parent = node;
                    node = tmp;
                }
//                case 3 叔叔节点是黑色的，且当前节点是右子节点
                setBlack(parent);//将父节点涂成黑色
                setRed(gparent);//将祖父节点图成红色
                leftRotate(gparent);//左旋
            }

        }

        setBlack(root);//将根节点设置为黑色
    }


```

#### **插入分为以下三种情况**

#### 6.3.1 **新节点没有父节点(即插入根节点)**

操作：将节点涂为红色插入根节点处，并改为黑色(使其符合性质1根节点为黑色)

![img](https://img-blog.csdn.net/20170305213841518)

#### 6.3.2 **新节点N的父亲节点为黑色**

此时不需要调整

![img](https://img-blog.csdn.net/20170305220933856)

#### 6.3.3 **新节点N的父亲节点为红色**

因为红黑树不允许有两个连续红色节点，所以要根据叔父节点的颜色来进行调整

##### 6.3.3.1 **新节点的叔父节点为红色**

将新节点的父亲结点和叔父节点涂为**黑色**，并将祖先节点G涂为**红色**，这样保证从G到任何NIL路径所包含的黑色节点数目与原来保持一致。由于把G变成了红色，如果G的父亲也为红色，则会违反性质导致连续两个红色节点，所以需要检查G是否违反红黑树性质。

![img](https://img-blog.csdn.net/20170305224233105)

##### 6.3.3.2 **新节点的叔父节点为黑色**

###### 6.3.3.2.1 **若新插入节点为父节点的左孩子**

将父节点P涂为黑色，祖先节点G涂为红色，然后对祖先节点进行一次右旋

![img](https://img-blog.csdn.net/20170305231103609)

###### 6.3.3.2.2 若新插入节点为父节点的右孩子

对父节点P进行一次左旋，问题转化为了左孩子情况。

![img](https://img-blog.csdn.net/20170305230905998)

#### 6.3.4 例子

下面举个例子，往一棵红黑树中插入元素，整棵树的变换如下图所示：

![图片.png](https://myblog-1252088789.cos.ap-chengdu.myqcloud.com/blog/%E5%9B%BE%E7%89%87_1585705330836.png)

### 6.4 删除节点

#### 步骤

> 红黑树删除操作也分为两步：
>
> 定位删除的位置
>
> 定位删除位置可以复用红黑树搜索的操作。
>
> 如果不存在目标结点，忽略本次操作；如果找到目标结点，删除后进行自平衡处理。
>
> 删除后实现自平衡
>
> 二叉搜索树删除的时候可能出现三种场景：
> 若删除结点无子结点，直接删除即可。
> 若删除结点只有一个子结点，用子结点替换删除结点。
> 若删除结点有两个子结点，用**后继结点（大于删除结点的最小结点）**替换删除结点。

具体应用，可以借助这张图理解：

![image-20210602213453937](https://gitee.com/top20chenql/md_imgs/raw/master/img/20210602213520.png)



![图片.png](https://myblog-1252088789.cos.ap-chengdu.myqcloud.com/blog/%E5%9B%BE%E7%89%87_1585705377851.png)

> 思路：下面的任何调整，只有一个目的，就是不断调整，直到调整到可以直接将D移除又不会影响红黑树特性的情况。但关键是**调整过程中红黑树特性也不会发生改变**。因为调整的话，还没删除，所以还是得维持还是红黑树

#### 替换删除节点

> 首先根据BST删除节点的规则，使用当前节点左子树的最大值节点或者右子树的最小值节点代替其删除（这两个节点是其子树中数值上最贴近当前节点数值的节点）。 这一点，只要懂了二叉查找树的删除操作就明白了，在这里不多说了。
>
> 如下图：
>
> 既然待删除节点是要被移走的，那肯定有一个节点要替换到它的位置上去。如何找到这个替换节点，这个过程和二叉查找树一模一样，要么在它的左子树下一直往右找到最大节点，要么在右子树下找到最小节点。（假如你已经明白二叉查找树的删除过程，那么我这段话就是多余的，直接往下看。）

![img](https://img-blog.csdnimg.cn/20190119231050243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc4NjI3NA==,size_16,color_FFFFFF,t_70)

> 下面的描述过程采用的是右子树的最小值节点代替。
>
> 当找到替换节点之后，现在需要考虑的情况就减少了，只可能会出现以下几种情况（因为需要满足红黑树特性）：
>
> 下面这三种情况，说的是新待删除节点的情况。什么是新待删除节点，就是**即将被替换到待删除位置的节点**。
>
> 　　1. 无子节点，节点为红色
>
> 　　2. 无子节点，节点为黑色
>
> 　　3. 只有右子节点，右子节点为红色，节点本身为黑色
>
> （因为D节点就是即将要替换到待删节点位置的节点，它同时又是右子树的最小值，既然是最小值了，它就不再可能拥有左子树了，所以只有可能有右子节点。另外，假如它有右节点且右节点的颜色是黑色，它自身颜色是红色，根本不成立。因为假如它自身为红色且又有黑孩子，那它必须要有两个黑孩子才满足红黑树性质，所以不满足。 那有没有可能，它自身是黑色且右孩子也为黑色呢？也不可能！因为它左孩子已经为空了，说明它从自身出发到左子树的叶子的距离就是1，假如它右孩子也为黑色，那它从自身出发到右子树叶子的距离肯定大于等于2了，明显不可能。
>
> 所以总的来说只可能有下面三种情况）

![img](https://img-blog.csdnimg.cn/20190119231507629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc4NjI3NA==,size_16,color_FFFFFF,t_70)

情况1，只需要直接删除节点就可以。

分析 ：删了一个红色新待删节点，不会影响红黑树性质

情况2，删除该D节点后，违反了红黑树特性5，需要调整（不考虑待删除节点为根节点的情况）

情况3，用右子节点R占据待删除节点D，再将其染成黑色即可，不违反红黑树特性。

分析：因为左边本来就是空了，其实右子树下即使有多少个黑色节点，也不会影响整体特性。

 

在这三种情况中，情况1和情况3比较简单，不需要多余的调整。情况2则需要后续的调整步骤使其满足红黑树特性。

 

3.2 调整红黑树

上述情况2的调整比较复杂。

下面对各种情况进行讲解。

根据红黑树的特性5，待删除节点必然有兄弟节点。

为什么这么说呢？因为我们已经假设上面的D节点不为根了，那说明它肯定有父亲。

首先它是没有孩子的，它下面直接就是叶子了，既然有父亲，不论它是父亲的左孩子或者右孩子，从父亲出发到它自身，黑色节点的个数为1.反证法，假如父亲只有它一个孩子，那说明父亲到另一边子树的叶子距离就为0，因为0个节点。这明显不符合，所以说明父亲肯定有两个孩子，那从而得知待删节点D必有兄弟。

 

下面根据其兄弟节点所在分支的不同，来分情况讨论。

图例：D表示当前节点，P表示父节点，B表示兄弟节点，BR表示兄弟节点的右子节点，BL表示兄弟节点的左子节点

（以下是以关注待删节点为父节点的左子节点进行描述，如果遇到关注节点为父节点的右子节点的情况，则镜像处理）

 

思路：下面的任何调整，只有一个目的，就是不断调整，直到调整到可以直接将D移除又不会影响红黑树特性的情况。但关键是调整过程中红黑树特性也不会发生改变。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMzkyMzgyLWRiMzQ2OGE1OTc3YWQ5OTgucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy8xMDAwL2Zvcm1hdC93ZWJw?x-oss-process=image/format,png)

#### 6.4.1  删除情景1：替换结点是红色结点

> 我们把替换结点换到了删除结点的位置时，由于替换结点时红色，删除也了不会影响红黑树的平衡，只要把替换结点的颜色设为删除的结点的颜色即可重新平衡。
>
> **处理：颜色变为删除结点的颜色**

#### 6.4.2  删除情景2：替换结点是黑结点

当替换结点是黑色时，我们就不得不进行自平衡处理了。我们必须还得考虑替换结点是其父结点的左子结点还是右子结点，来做不同的旋转操作，使树重新平衡。

##### 6.4.2.1 替换结点是其父结点的左子结点

###### 6.4.2.1.1  兄弟节点为红色

![img](https://img-blog.csdnimg.cn/20190119231619958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc4NjI3NA==,size_16,color_FFFFFF,t_70)

> 将父节点染成红色，兄弟节点染成黑色，然后对父节点进行左旋操作。此时就转换为了下面的（4），之后按照（4）继续进行调整。
>
>  
>
> 分析：这种情况，树的整体高度为2，变色左旋之后，整体高度还是保持在2.

###### 6.4.2.1.2 兄弟节点为黑色，远侄节点为红色

![img](https://img-blog.csdnimg.cn/20190119231655385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc4NjI3NA==,size_16,color_FFFFFF,t_70)

> 　这种情况下，不需要考虑父节点的颜色。
>
> 　　第一步：将父节点P与兄弟节点B的颜色互换 ,这个过程父亲染黑
>
> 　　第二步：将兄弟节点的右子节点BR染成黑色
>
> 　　第三步：对父节点P进行左旋操作
>
> 可以看到，原本高度就是符合红黑树特性的，左右子树的高度都为1，因为黑色节点只有一个。经过这三步的调整后，直接删除节点D后仍然满足红黑树的特性，调整完成，跳出算法循环。

###### 6.4.2.1.3 兄弟节点为黑色，远侄节点为黑色，近侄节点为红色

![img](https://img-blog.csdnimg.cn/20190119231723520.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc4NjI3NA==,size_16,color_FFFFFF,t_70)

> 这种情况下，兄弟节点的左节点染成黑色。兄弟节点染红。然后对兄弟节点做右旋。
>
> 此时的状况就和（2）一样了。之后就通过（2）的调整方式进行调整。

###### 6.4.2.1.4 父节点为红色，兄弟节点为黑色，兄弟节点无子节点

![img](https://img-blog.csdnimg.cn/20190119231757545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc4NjI3NA==,size_16,color_FFFFFF,t_70)

> 这种情况下，将父节点P染成黑色，再将兄弟节点染成红色。
>
> 经过这样的操作后，除去节点D后，以P为根节点的子树的黑节点深度并没有发生变化。调整完成。
>
>  
>
> 分析：
>
> （怎么理解这一个操作？可以看左边，没调整前，P的左右子树的黑色结点的数目都是1，是相同的，符合红黑树的性质：从任一节点到其叶子的所有简单路径都包含相同数目的黑色节点。然后再看右边，调整后，删掉D之后，P结点的左右子树的黑色结点都是0个，仍然满足性质，所以调整完成。）
>
> 

###### 6.4.2.1.5 父节点为黑色，兄弟节点为黑色，兄弟节点无子节点

![img](https://img-blog.csdnimg.cn/20190119231853936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjc4NjI3NA==,size_16,color_FFFFFF,t_70)

> 这种情况下，为了在删除节点D后使以P为根节点的子树能满足红黑树特性5，将兄弟节点B染成红色。但是这样操作后，以P为根节点的子树的黑色节点深度变小了。所以需要继续调整。
>
> 　　因为P节点子树的黑色深度发生了减少，可以把其当作待删除节点，那么此时就以P节点为关注节点进行进一步调整（继续向上调整）。 这句话的意思我们再以P为起始点，继续根据情况进行平衡操作（这句话的意思就是把P当成D（只是不要再删除P了），再看是这五种中的哪种情况，再进行对应的调整，这样一直向上，直到新的起始点为根节点或者关注节点不为黑色）
>
>  
>
> 第五个这种情况，不会一直连续回溯的。假如能一直回溯，指针向上走之后，兄弟节点会一直都没有右孩子吗？不存在的。假如有这种情况，说明树的路径长度已经严重往左倾斜，肯定不可能。所以回溯这个情况只会回溯一次，不会连续回溯。第五个这种情况出现之后，下一次进入算法循环，肯定就是进入其他情况，直到遇到break，跳出循环，终止整个算法过程。
>
> 



###### 6.4.2.1.6 检查根节点及删除节点

> 　经过上述的调整后，此时基本满足了红黑树的特性。但是存在根节点变成红色的情况。所以需要将根节点染成黑色的操作。 最后，执行删除操作，将待删除节点删掉。（当然从编程上，你也可以调整指针先把待删除节点移掉，然后再开始平衡调整过程。注意这里说的平衡调整，并不是AVL树的绝对平衡调整，而是满足红黑树特性的平衡调整。红黑树的平衡和AVL的平衡是有区别的。

##### 6.4.2.2 **替换结点是其父结点的右子结点**

好啦，右边的操作也是方向相反，不做过多说明了，相信理解了删除情景2.1后，肯定可以理解2.2。

###### 6.4.2.2.1 **替换结点的兄弟结点是红结点**

> 处理：
>
> - **将S设为黑色**
> - **将P设为红色**
> - **对P进行右旋，得到情景2.2.2.3**
> - **进行情景2.2.2.3的处理**

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMzkyMzgyLTM4NzY2NGM3NzFiMjFmMWIucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy8xMDAwL2Zvcm1hdC93ZWJw?x-oss-process=image/format,png)

图25 删除情景2.2.1

###### 6.4.2.2.2 **替换结点的兄弟结点是黑结点**，其左子结点是红结点，右子结点任意颜色

> **处理：**
>
> - **将S的颜色设为P的颜色**
> - **将P设为黑色**
> - **将SL设为黑色**
> - **对P进行右旋**

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMzkyMzgyLWIxZWE1MmM4MjNjZTBiMGIucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy8xMDAwL2Zvcm1hdC93ZWJw?x-oss-process=image/format,png)

图26 删除情景2.2.2.1

###### 6.4.2.2.3 **替换结点的兄弟结点的左子结点为黑结点，右子结点为红结点**

> **处理：**
>
> - **将S设为红色**
> - **将SR设为黑色**
> - **对S进行左旋，得到情景2.2.2.1**
> - **进行情景2.2.2.1的处理**

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMzkyMzgyLWVkY2I0ZWE2YWM4N2UzNDIucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy8xMDAwL2Zvcm1hdC93ZWJw?x-oss-process=image/format,png)

图27 删除情景2.2.2.2

###### 6.4.2.2.4 **替换结点的兄弟结点的子结点都为黑结点**

> **处理：**
>
> - **将S设为红色**
> - **把P作为新的替换结点**
> - **重新进行删除结点情景处理**

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMzkyMzgyLTY1NTljNGNjY2YzZGY4MWMucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy83NDgvZm9ybWF0L3dlYnA?x-oss-process=image/format,png)

图28 删除情景2.2.2.3







#### 代码

```java
package com.kun.kunspringbootweb.foo.tree;
 
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.ConcurrentHashMap;
 
 
/**
 * 红黑树-Java实现例子
 *
 *
 * @author xuyaokun
 * @date 2019/1/14 17:06
 */
public class MyRBTree<T extends Comparable<T>, D> {
 
    private RBNode<T, D> root;//根节点
    /**
     * 节点的颜色
     */
    private static final Boolean RED = false;
    private static final Boolean BLACK = true;
 
    public class RBNode<T extends Comparable<T>, D> {
 
        private Boolean color;//节点颜色
        private T key;//键值
        private D data;//具体的数据
        private RBNode<T, D> parent;
        private RBNode leftChild;
        private RBNode rightChild;
 
 
        public RBNode(Boolean col, T key, D data, RBNode paret, RBNode leftChild, RBNode rightChild) {
            this.color = col;
            this.key = key;
            this.data = data;
            this.parent = parent;
            this.leftChild = leftChild;
            this.rightChild = rightChild;
 
        }
 
    }
 
    /**
     * 获取父亲
     *
     * @param node
     * @return
     */
    public RBNode<T, D> parentOf(RBNode<T, D> node) {
        if (node != null) {
            return node.parent;
 
        }
 
        return null;
 
    }
 
    /**
     * 获取颜色
     *
     * @param node
     * @return
     */
    public Boolean colorOf(RBNode<T, D> node) {
        if (node != null) {
            return node.color;
 
        }
        return BLACK;
 
    }
 
    public void setParent(RBNode<T, D> node, RBNode<T, D> parent) {
        if (node != null) {
            node.parent = parent;
        }
 
    }
 
    public void setColor(RBNode<T, D> node, Boolean color) {
        if (node != null) {
            node.color = color;
 
        }
 
    }
 
    public Boolean isRed(RBNode<T, D> node) {
        return (node != null && node.color == RED) ? true : false;
 
    }
 
    public Boolean isBlack(RBNode<T, D> node) {
        return !isRed(node);
 
    }
 
    public void setRed(RBNode<T, D> node) {
        if (node != null) {
            node.color = RED;
        }
    }
 
    public void setBlack(RBNode<T, D> node) {
        if (node != null) {
            node.color = BLACK;
        }
 
    }
 
    /**
     * 根据key获取数据
     *
     * @param key
     * @return
     */
    public D get(T key){
        RBNode node = search(key, root);
        return node == null ? null : (D) node.data;
    }
 
    //寻找为key值的节点
    public RBNode<T, D> search(T key, RBNode<T, D> node) {
 
        if (node != null) {
            //查找的过程，就是一直递归比较到叶子为止
            int com = key.compareTo(node.key);
            if (com < 0) {
                return search(key, node.leftChild);
            } else if (com > 0) {
                return search(key, node.rightChild);
            } else {
                return node;
            }
 
        }
        return null;
 
 
    }
 
    //寻找后继节点，即大于该节点的最小节点
    public RBNode<T, D> min(RBNode<T, D> node) {
 
        //一直往左走，最左端的就是最小值，这是二叉树的性质
        if (node.leftChild == null) {
            return node;
        }
        while (node.leftChild != null) {
            node = node.leftChild;
        }
 
        return node;
    }
 
    /**
     * 寻找待删节点的后继节点
     * （因为这个节点即将要被删了，所以要选个后继节点补到这个位置来，
     *  选择节点的规则：
     *  这个规则和普通二叉树是一样的，要么就是找左子树的最大值，要么就是右子树的最小值）
     *
     * @param node
     * @return
     */
    public RBNode successor(RBNode<T, D> node) {
 
        if (node.rightChild != null) {
            return min(node.rightChild);
        }
        //下面这里是不会进入的，因为只有node的两个孩子都不为null时才会进入这个方法
        RBNode<T, D> y = node.parent;
        while ((y != null) && (y.rightChild == node)) {
            node = y;
            y = y.parent;
 
        }
        return y;
 
    }
 
    /**
     * 对某个节点进行左旋
     * （当前节点就是父亲节点，整体过程就是 父亲下沉，右孩子上升，然后右孩子的左节点变成了原父亲的右节点）
     *
     * @param x
     */
    public void leftRonate(RBNode<T, D> x) {
 
        //右孩子
        RBNode<T, D> y = x.rightChild;
 
        if (y.leftChild != null) {
            //当前节点 变成了 右孩子的左节点的父亲
            y.leftChild.parent = x;
        }
        x.rightChild = y.leftChild;
        y.leftChild = x;
        //当前的父亲变成了右孩子的父亲
        y.parent = x.parent;
 
        if (x.parent != null) {
            if (x.parent.leftChild == x) {
                x.parent.leftChild = y;
            } else {
                x.parent.rightChild = y;
            }
        } else {
            this.root = y;
        }
        x.parent = y;
 
    }
 
    //对某个节点进行右旋
    public void rightRonate(RBNode<T, D> x) {
        RBNode<T, D> y = x.leftChild;
 
        if (y.rightChild != null) {
            y.rightChild.parent = x;
 
        }
 
        y.parent = x.parent;
        x.leftChild = y.rightChild;
        y.rightChild = x;
 
        if (x.parent != null) {
            if (x.parent.leftChild == x) {
                x.parent.leftChild = y;
 
            } else {
                x.parent.rightChild = y;
 
            }
 
        } else {
            this.root = y;
 
        }
        x.parent = y;
 
    }
 
 
 
    /**
     *
     * 插入后的自平衡过程
     *
     * （为什么用这个方法名，因为HashMap源码也是用这个源码名）
     *
     * @param node 新插入的节点
     */
    public void balanceInsertion(RBNode<T, D> node) {
 
        RBNode<T, D> parent, gparent;//父亲与祖父
 
        //一开始插入的节点首先肯定是红色，假如父亲不为空且父亲也是红色，那就出现了“双红情况”
        //必须做调整，进入循环
        //假如父亲是黑色，没必要调整，为什么？
        // 因为加一个红节点，不会影响这条路径上的黑色节点个数发生变化，所以不会影响红黑树的性质
        while (((parent = parentOf(node)) != null) && isRed(parent)) {
 
            //拿到父亲的父亲，也就是祖父
            gparent = parentOf(parent);
 
            //根据祖父来判断，父亲是祖父的左子树还是右子树，确定了之后的目的是为了拿到叔父
            if (gparent.leftChild == parent) {
                //假如父亲是祖父的左孩子，那通过祖父的右孩子指针就能拿到叔父
                RBNode<T, D> uncle = gparent.rightChild;
                //进一步，再分两种情况，会发生以下两种情况的前提是父亲为红色 ：
                if (isRed(uncle)) {
                    //叔父是红色
                    //父亲变黑，叔父变黑，祖父变红 （为何要这三步，这就是规律，用笔和纸画画就知道）
                    // 实在看不懂参考我的笔记：http://note.youdao.com/noteshare?id=14243cb721319c19ef8f79cadd2a2c81&sub=0B35BC1D6FD747DAB0C373910D1DBAB5
                    setBlack(parent);
                    setBlack(uncle);
                    setRed(gparent);
                    //回溯，向上，这一步指针赋值，把祖父变成当前节点，继续向上判断，直到终止
                    node = gparent;
                    //插入操作，回溯过程进入这个代码if-else分支，最多一次，为何？
                    //因为叔父一开始是红色，那说明祖父必为黑色，那祖父的兄弟也肯定是黑色，因为黑色的兄弟节点，必然同色
                    //进入一次之后，父亲变成了当前节点，原来的祖父变成了父亲，那说明新父亲不会与新叔父同为红色。
                    continue;
 
                } else {
                    //叔父是黑色，父亲为红
                    if (parent.rightChild == node) {
                        //假如当前节点是父亲的右孩子
                        //父亲要左旋
                        leftRonate(parent);
                        RBNode<T, D> temp = node;
                        node = parent;
                        parent = temp;
 
                    }
                    //因为上面发生了指针调换，这里parent其实已经指当前节点的指针
                    // 所以是当前节点位置上升变黑，父亲下沉还是红色，祖父变红
                    setBlack(parent);
                    setRed(gparent);
                    //祖父右旋
                    //这里为什么祖父还要右旋一次呢？
                    /*
                             黑祖               黑祖
                            /    \             /   \
                         红父    黑叔  -->  红插   黑叔
                            \               /
                            红插          红父
                         可以看到上面，经过了一次旋转之后，平衡性仍然满足，但是颜色就不对了，仍然存在双红情况
                         其实理解了AVL树的平衡调整，这里其实也是一个“双旋转”的过程，只有被删节点与父亲不同侧时才需要双旋
                         继续接着上面的双红情况，因为颜色不对，这时需要变色
                                    黑祖          红祖
                                   /   \          /   \
                                红插   黑叔 --> 黑插  黑叔
                               /                /
                            红父              红父
                          可以看到，变色之后，右边的子树和左边子树的黑色节点个数保持一致，明显和原来不同，原来的图，看左上角，右子树的黑色节点要多一个
                          原来的树肯定是满足红黑树性质的，所以这里只需要做一次简单的右旋，就可以让右子树的黑色节点个数再次比左边多一个，满足了原来的情况
                     */
                    rightRonate(gparent);
 
                }
 
            } else {
                //同理，先找到叔父
                RBNode<T, D> uncle = gparent.leftChild;
                if (isRed(uncle)) {
                    //这个过程其实和上面的是 一致的，不需要旋转，只需要重新染色即可
                    setBlack(parent);
                    setBlack(uncle);
                    setRed(gparent);
                    node = gparent;
                    continue;
 
                } else {
                    if (parent.leftChild == node) {
                        //假如当前插入节点是父亲的左孩子，那就对父亲做右旋
                        //左孩子上升，父亲下沉
                        rightRonate(parent);
                        RBNode<T, D> temp = node;
                        node = parent;
                        parent = temp;
                    }
                    //同理，祖父左旋
                    setBlack(parent);
                    setRed(gparent);
                    leftRonate(gparent);
 
                }
 
            }
 
        }
 
        //调整后，假如都调整到根处了，必须要再次检验，让根为黑色，让它继续满足红黑树的性质
        if (root == node) {
            setBlack(node);
        }
 
    }
 
    /**
     * 红黑树删除后的平衡调整
     * （删除操作比较复杂，所以我加了很多过程状态追踪）
     *
     * @param node
     * @param parent
     *
     *               入参只可能是下面这两种情况：
     *               1. node=替换节点 parent=替换节点的父亲节点
     *               2. node=替换节点的孩子节点 parent=替换节点
     *               3. node=替换节点的孩子节点 parent=替换节点的父节点
     *
     *               无论是上面哪种情况，都满足：node和parent是儿子父亲的关系
     *
     *               首先要清楚，什么情况下会进入到这个方法？
     *               1.待删节点是黑色节点（且待删节点只有一个子树）
     *               或者
     *               2.替换节点是黑色节点(待删节点的左右子树都不为空)
     *
     *               下面仔细分析下上面两种情况，为何只有这两种情况下，才有必要进行调整。
     *               对于上面的情况1：
     *               待删节点只有一个子树，说明只有一条路径，待删节点移除掉之后，只会影响一条路径上的黑色节点个数。
     *               回忆下红黑树的性质，同一个节点出发直到叶子，每一个不同的路径下的黑色节点个数必须是相同的。
     *               那既然它只有一个子树，说明只有一条路径。假如待删节点是红色，它移除掉之后，不会影响这条路劲下的黑色节点个数，所以不需要调整。
     *               反之，假如它是黑色，它一旦被移除，这一条路径上的黑色个数就减少了，这样会导致这一条路径的黑色节点直接减一
     *               这样就会导致这一条路径和 其他由树根出发的路径相比，不再相等。
     *
     *               对于上面的情况2：
     *               因为待删节点下，有两个子树，那要让树继续保持二叉树的关系，那待删位置上必须放入一个符合规则的元素。
     *               符合什么规则呢？也就是必须比左子树大，比右子树小，所以我们编程上通常选右子树的最小值。
     *               待删元素被删，就要选右子树的最小值放到待删元素位置，那替换节点的指针就会丢失，因为做了移动。
     *               既然右子树中有个元素被移除了，假如这个被移除指针的替换节点，是红色，不会对整棵树的平衡性有任何影响。
     *               但假如这个替换节点是黑色，一旦被移除，会导致右子树的黑色个数减一，不再相等，所以需要调整。
     *
     *      对于一次调整过程，最多不会超过三次，这是为什么？
     *      上述的情况1比较简单，不需要做任何旋转，只需要染色即可。
     *      复杂的是情况2。。
     *          情况2又可以分为细分两种情况：
     *              1.替换节点在新父亲的左侧
     *              2.替换节点在新父亲的右侧
     *              (只要理解了其中一种情况，另一种其实也清楚了)
     *
     *
     *              下面只选其中一种情况，做总结
     *              对于替换节点在新父亲的左侧这种情况，又可以细分成几种情况（下面这几种情况，才是我觉得红黑树中最难理解的部分）：
     *                  1.兄弟节点是红色：兄弟变黑，父亲变红，父亲左旋
     *                  2.兄弟节点是黑色
     *                    2.1.兄弟节点的左右孩子都是黑色：兄弟染红，整体指针（包括替换节点和其parent）向上回溯一步
     *                    2.2.兄弟节点的左孩子是红色，右孩子是黑色：兄弟染红，左孩子染黑，兄弟右旋
     *                    2.3.兄弟节点的右孩子是红色：父亲的颜色赋值到兄弟,父亲染黑，兄弟的右孩子染黑，父亲左旋
     */
 
    public void balanceDeletion(RBNode<T, D> node, RBNode<T, D> parent) {
 
        //先看下调整之前的树结构
        System.out.println("先看下调整之前的树结构");
        this.printTreeLevel2();
 
        RBNode<T, D> other;
        while (isBlack(node) && node != this.root) {
 
            //假如替代节点的颜色也为黑，这里为什么要用“也”字，能进这个方法，肯定说明被删节点也是黑色
            //替代节点也是黑色，那肯定要做调整了，不然整条路径，就少了一个黑色节点，最终肯定是不符合红黑树条件的
 
            if (parent.leftChild == node) {
                //假如替代节点是其新父亲的左节点，那就通过右指针拿到其兄弟节点
                other = parent.rightChild;
 
                System.out.println("当前parent：" + parent.key + " other(兄弟节点):" + other.key);
 
                if (isRed(other)) {
                    //假如兄弟是红色，那么父亲肯定是黑色
 
                    System.out.println("兄弟当前是红色");
                    System.out.println("进入balanceDeletion的while（情况2-L-a:兄弟是红色）");
                    System.out.println("----父亲染红，other染黑，父亲左旋，然后continue");
 
 
                    //兄弟与父亲调换颜色，父亲做左旋
                    setRed(parent);
                    setBlack(other);
                    leftRonate(parent);
 
                    this.printTreeLevel2();
 
                    continue;
 
 
                } else {
                    if (isBlack(other.leftChild) && isBlack(other.rightChild)) {
                        //假如兄弟节点没有任何孩子节点，也会进入这个代码分支，因为叶子也相当于是黑色的
 
                        //other就是替换节点的兄弟节点
                        System.out.println("兄弟节点当前的左右孩子都是黑色");
                        System.out.println("进入balanceDeletion的while（情况2-L-b:兄弟的左右孩子都是黑色）");
                        System.out.println("----other染红，父亲指针向上回溯");
 
                        //other染红，父亲指针向上回溯
                        setRed(other);
                        node = parent;
                        parent = parentOf(node);
 
                        this.printTreeLevel2();
 
 
                    } else if (isRed(other.leftChild) && isBlack(other.rightChild)) {
 
                        System.out.println("other当前的左孩子是红色，右孩子是黑色");
                        System.out.println("进入balanceDeletion的while（情况2-L-c:兄弟的左孩子是红色，右孩子是黑色）");
                        System.out.println("----other染红，other的左节点染黑，other做右旋");
 
                        setRed(other);
                        setBlack(other.leftChild);
                        rightRonate(other);
 
                        this.printTreeLevel2();
 
 
                    } else if (isRed(other.rightChild)) {
 
                        System.out.println("other右孩子是红色");
                        System.out.println("进入balanceDeletion的while（情况2-L-d:兄弟的右孩子是红色）");
                        System.out.println("----父亲的颜色赋值到other,父亲染黑，other的右孩子染黑，父亲左旋，跳出while循环");
 
                        setColor(other, colorOf(parent));
                        setBlack(parent);
                        setBlack(other.rightChild);
                        leftRonate(parent);
 
                        this.printTreeLevel2();
 
                        break;
 
                    }
 
                }
 
            } else {
                other = parent.leftChild;
 
                System.out.println("当前parent：" + parent.key + " other:" + other.key);
 
                if (isRed(other)) {
 
                    System.out.println("other当前是红色");
                    System.out.println("进入balanceDeletion的while（情况2-R-a:兄弟是红色）----other染黑，parent变红,parent右旋");
 
                    setBlack(other);
                    setRed(parent);
                    rightRonate(parent);
 
                    this.printTreeLevel2();
 
                    continue;
 
                } else {
 
                    if (isBlack(other.leftChild) && isBlack(other.rightChild)) {
 
                        System.out.println("other当前的左孩子是黑色，other的右孩子是黑色");
                        System.out.println("进入balanceDeletion的while（情况2-R-b:兄弟的左右孩子都是黑色）----other变红，指针回溯");
 
                        setRed(other);
                        node = parent;
                        parent = parentOf(node);
 
                        this.printTreeLevel2();
 
 
                    } else if (isRed(other.rightChild) && isBlack(other.leftChild)) {
 
                        System.out.println("other当前的右孩子是红色，other的左孩子是黑色");
                        System.out.println("进入balanceDeletion的while（情况2-R-c:兄弟的右孩子是红色，左孩子是黑色）----parent变红，other的右孩子变黑，然后other做左旋");
 
                        setRed(parent);
                        setBlack(other.rightChild);
                        leftRonate(other);
 
                        this.printTreeLevel2();
 
 
                    } else if (isRed(other.leftChild)) {
 
                        System.out.println("other的左孩子是红色");
                        System.out.println("进入balanceDeletion的while（情况2-R-d:兄弟的左孩子是红色）----父亲的颜色赋值到other,父亲染黑，other的左孩子染黑，父亲右旋，跳出while循环");
 
                        setColor(other, colorOf(parent));
                        setBlack(parent);
                        setBlack(other.leftChild);
                        rightRonate(parent);
 
                        this.printTreeLevel2();
 
                        break;
 
                    }
 
                }
 
            }
 
        }
 
        //在这里，node其实是即将放入被删位置的替代节点
        //假如node是红色，那同时被删节点是黑色，
        // 那说明，直接把node的颜色由红变黑，就直接满足了，不需要做任何旋转
        if (node != null){
            System.out.println("节点：" + node.key + "染黑");
        }
        setBlack(node);
 
        this.printTreeLevel2();
 
        System.out.println("调整完成！！！！！！！");
 
    }
 
 
    //红黑树添加操作
    public void insertNode(T key, D data) {
 
        int com;
        RBNode<T, D> x = this.root;
        RBNode<T, D> y = null;
 
        //这个过程和二叉查找树的过程是一样的，从上循环到底，直到找到为止
        while (x != null) {
            y = x;
            com = key.compareTo(x.key);
 
            if(com == 0){
                //说明相等，找到了，直接替换新值，返回
                //TODO
 
                return ;
            }
 
            if (com < 0) {
                x = x.leftChild;
            } else {
                x = x.rightChild;
            }
        }
 
        //生成一个新的节点
        RBNode<T, D> node = new RBNode<T, D>(BLACK, key, data, null, null, null);
        //通过上面的比较，已经找到了父亲
        node.parent = y;
 
        if (y != null) {
            //再次做比较，决定要把新节点放在父亲的哪一边
            com = node.key.compareTo(y.key);
            if (com < 0) {
                y.leftChild = node;
            } else {
                y.rightChild = node;
            }
        } else {
            //假如找到的父亲为空，那说明肯定之前就没有根，是空树
            //把这个新节点作为根
            this.root = node;
 
        }
        //根据红黑树的性质，把默认节点设置为红色，向上回溯，更容易列举可能出现的情况，
        // 所以这里新节点都默认设置成红色
        setRed(node);
 
        //接下来这个就是最关键的方法 ，插入后的自平衡过程，调整让它保持红黑树的性质
        balanceInsertion(node);
 
    }
 
    public void insert(T key, D data) {
        insertNode(key, data);
    }
 
    public void add(T key, D data) {
        insertNode(key, data);
    }
 
 
    /**
     * 红黑树删除操作
     *
     * @param node  传入的是待删除节点
     */
    public void delete(RBNode<T, D> node) {
 
        RBNode<T, D> child, parent, replace;
        Boolean color = true;
 
        //删除从整体上也分两种情况，然后两种情况下再细分
 
        //假如待删除节点的双节点都不为空，这种情况较复杂
        if (node.leftChild != null && node.rightChild != null) {
 
            //找到了替换节点，就是要接替待删节点指针的新节点
            replace = successor(node);
            //找到替换节点的父亲节点
            parent = parentOf(replace);
            //因为替换节点已经是右子树中的最小值了，所以只有右孩子
            child = replace.rightChild;
 
            //在这里为什么要获取替换节点的颜色呢？
            //可以这样想，因为替换节点的指针最终肯定是会丢失的，因为替换节点即将接受待删节点的指针，所以替换节点的指针就不再保留了
            //既然不再保留，那说明原来替换节点这里肯定就少了一环，少了一个节点，所以这里就有判断它颜色的必要
            //假如少的恰恰是黑色，那说明它会影响整棵树的平衡性，不再满足红黑树性质
            color = colorOf(replace);
 
            if (node == parentOf(replace)) {
                //假如替换节点的父亲节点就是当前待删除节点
                //那就直接把待删除节点的指针赋值给parent
                parent = replace;
 
            } else {
                //假如替换节点的父亲不是待删除节点的父亲
                if (child != null) {
                    //因为替换节点待会是要被删掉的，因为它的值会被放置到待删除节点中，然后把替换节点删除就相当于完成整个删除操作
                    //所以要为替换节点的孩子节点找到新父亲
                    setParent(child, parentOf(replace));
                }
                //然后替换节点的右孩子设置成替换节点的父亲的左孩子
                replace.parent.leftChild = child;
                replace.rightChild = node.rightChild;
                setParent(node.rightChild, replace);
            }
 
            //把目标删除节点node的父亲设置成替换节点的父亲
            setParent(replace, parentOf(node));
            replace.leftChild = node.leftChild;
            setParent(node.leftChild, replace);
            //除了指针的调整，颜色也要覆盖，替换节点既然来到了待删节点的位置，那么颜色也要沿用之前的颜色，这样才能满足整棵树的性质
            setColor(replace, colorOf(node));
 
            if (parentOf(node) != null) {
                //待删节点的父亲节点假如不为空，那就要调整父亲节点的左右孩子指针
                if (node.parent.leftChild == node) {
                    node.parent.leftChild = replace;
                } else {
                    node.parent.rightChild = replace;
                }
 
            } else {
                this.root = replace;
            }
            //上面整个过程就是用replace的指针完全取代了node节点，到此为止，node节点就是一个孤立节点了，就算是删除了
 
            if (color == BLACK) {
                balanceDeletion(child, parent);
            }
 
        } else {
 
            //假如待删节点只有左子树或者右子树
            if (node.leftChild != null) {
                replace = node.leftChild;
            } else {
                replace = node.rightChild;
            }
            //找到待删节点的父亲节点
            parent = parentOf(node);
 
            if (parent != null) {
                //判断待删节点属于父亲的左还是右
                if (parent.leftChild == node) {
                    parent.leftChild = replace;
                } else {
                    parent.rightChild = replace;
                }
            } else {
                //假如待删节点的父亲为空，那说明它原来就是根
                //它被删了，所以孩子升为根
                this.root = replace;
            }
 
            //把parent设置成replace的父亲
            setParent(replace, parent);
 
            color = colorOf(node);
            child = replace;
            //假如待删节点是黑色节点，那说明本次删除肯定会影响红黑树的性质
            //删黑色节点，需要调整平衡，反之，删除红色节点，不需要调整
            if (color == BLACK) {
                balanceDeletion(child, parent);
            }
 
        }
 
 
    }
 
    public void delete(T key) {
        RBNode<T, D> node;
        if ((node = search(key, this.root)) != null) {
            delete(node);
        }
 
    }
 
    public void remove(T key) {
        RBNode<T, D> node;
        if ((node = search(key, this.root)) != null) {
            delete(node);
        }
 
    }
 
    //前序遍历
    public void preOrder(RBNode<T, D> node) {
        if (node != null) {
 
            System.out.print(node.key + " ");
            preOrder(node.leftChild);
            preOrder(node.rightChild);
 
        }
 
 
    }
 
    public void preOrder() {
        preOrder(this.root);
 
    }
 
    //中序遍历
    public void inOrder(RBNode<T, D> node) {
        if (node != null) {
            inOrder(node.leftChild);
            System.out.print(node.key + " ");
            inOrder(node.rightChild);
 
        }
 
    }
 
    public void inOrder() {
        inOrder(this.root);
 
    }
 
    //后序遍历
    public void postOrder(RBNode<T, D> node) {
        if (node != null) {
            postOrder(node.leftChild);
            postOrder(node.rightChild);
            System.out.print(node.key + " ");
 
        }
 
    }
 
    public void postOrder() {
        postOrder(this.root);
 
    }
 
    /**
     * 打印出整棵树的层级结构，为了方便跟踪旋转的过程
     *
     */
    public void printTreeLevel(){
 
        System.out.println("开始输出树的层级结构");
        ConcurrentHashMap<Integer, List<RBNode>> map = showTree();
        int size = map.size();
 
        for (int i = 0; i < map.size(); i++) {
            System.out.println();
            for (int j = 0; j < map.get(i).size(); j++) {
                System.out.print( makeSpace2(size, i) +
                        (map.get(i).get(j).key == null ? " " : (map.get(i).get(j).key) + (map.get(i).get(j).color? "(黑)":"(红)")) + makeSpace2(size, i));
 
            }
            System.out.println();
        }
        System.out.println("结束输出树的层级结构");
 
    }
 
    public void printTreeLevel2(){
 
        System.out.println("开始输出树的Graphviz结构");
        ConcurrentHashMap<Integer, List<RBNode>> map = showTree();
        int size = map.size();
        System.out.println("digraph kunghsu{");
        for (int i = 0; i < map.size(); i++) {
            for (int j = 0; j < map.get(i).size(); j++) {
 
                if(map.get(i).get(j).key != null){
                    System.out.println(map.get(i).get(j).key + " [color="  + (map.get(i).get(j).color == RED?"red":"black")  + " style=filled fontcolor=white] ");
                }
            }
        }
 
        for (int i = 0; i < map.size(); i++) {
            for (int j = 0; j < map.get(i).size(); j++) {
                String content = "";
 
                if(map.get(i).get(j).key != null){
                    if(map.get(i).get(j).leftChild != null){
                        System.out.println(map.get(i).get(j).key + "->" + map.get(i).get(j).leftChild.key + "[label=left]");
                    }
                    if(map.get(i).get(j).rightChild != null){
                        System.out.println(map.get(i).get(j).key + "->" + map.get(i).get(j).rightChild.key + "[label=right]");
                    }
                }
            }
        }
        System.out.println("}");
 
        System.out.println("结束输出树的Graphviz结构");
 
    }
 
    /**
     * 为了让输出更有结构感，在元素前拼接一些空格，对齐
     *
     * @param size
     * @param index
     * @return
     */
    public String makeSpace2(int size, int index){
        StringBuilder builder = new StringBuilder();
        for (int i = 0; i < 1 << (size - index); i++) {
            builder.append("  ");
        }
        return builder.toString();
    }
 
    public ConcurrentHashMap<Integer, List<RBNode>> showTree(){
 
        ConcurrentHashMap<Integer, List<RBNode>> map = new ConcurrentHashMap<>();
        showTree(root, 0, map);
        return  map;
    }
 
    public void showTree(RBNode root, int count, ConcurrentHashMap<Integer, List<RBNode>> map){
 
        if(map.get(count) == null){
            map.put(count, new ArrayList<>());
        }
        map.get(count).add(root);
 
        if(root.leftChild != null){
            showTree(root.leftChild, count+1 , map);
        }else{
            //假如为空，也添加到map中，因为我要做格式化控制，空的，我也要知道它这个位置是空的
            if(map.get(count+1) == null){
                map.put(count+1, new ArrayList<>());
            }
            map.get(count+1).add(new RBNode(false, null, null, null, null, null));
        }
        if(root.rightChild != null){
            showTree(root.rightChild, count+1 , map);
        }else{
            if(map.get(count+1) == null){
                map.put(count+1, new ArrayList<>());
            }
            map.get(count+1).add(new RBNode(false, null, null, null, null, null));
        }
    }
}
```

## 7、remove 方法

```java
/**
 * 移除某个节点
 */
public V remove(Object key) {
    Node<K,V> e;
    return (e = removeNode(hash(key), key, null, false, true)) == null ?
        null : e.value;
}
 
final Node<K,V> removeNode(int hash, Object key, Object value,
                           boolean matchValue, boolean movable) {
    Node<K,V>[] tab; Node<K,V> p; int n, index;
    // 1.如果table不为空并且根据hash值计算出来的索引位置不为空, 将该位置的节点赋值给p
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (p = tab[index = (n - 1) & hash]) != null) {
        Node<K,V> node = null, e; K k; V v;
        // 2.如果p的hash值和key都与入参的相同, 则p即为目标节点, 赋值给node
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            node = p;
        else if ((e = p.next) != null) {
            // 3.否则将p.next赋值给e，向下遍历节点，p是待删节点的上个节点
            // 3.1 如果p是TreeNode则调用红黑树的方法查找节点
            if (p instanceof TreeNode)
                node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
            else {
                // 3.2 否则，进行普通链表节点的查找
                do {
                    // 当节点的hash值和key与传入的相同,则该节点即为目标节点
                    if (e.hash == hash &&
                        ((k = e.key) == key ||
                         (key != null && key.equals(k)))) {
                        node = e;	// 赋值给node, 并跳出循环
                        break;
                    }
                    p = e;  // p节点赋值为本次结束的e，在下一次循环中，e为p的next节点
                } while ((e = e.next) != null); // e指向下一个节点
            }
        }
        // 4.如果node不为空(即根据传入key和hash值查找到目标节点)，则进行移除操作
        if (node != null && (!matchValue || (v = node.value) == value ||
                             (value != null && value.equals(v)))) {
            // 4.1 如果是TreeNode则调用红黑树的移除方法
            if (node instanceof TreeNode)
                ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
            // 4.2 如果node是该索引位置的头节点则直接将该索引位置的值赋值为node的next节点，
            // “node == p”只会出现在node是头节点的时候，如果node不是头节点，则node为p的next节点
            else if (node == p)
                tab[index] = node.next;
            // 4.3 否则将node的上一个节点的next属性设置为node的next节点,
            // 即将node节点移除, 将node的上下节点进行关联(链表的移除)
            else
                p.next = node.next;
            ++modCount;
            --size;
            afterNodeRemoval(node); // 供LinkedHashMap使用
            // 5.返回被移除的节点
            return node;
        }
    }
    return null;
}
```

## 8、put 方法

```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
 
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 1.校验table是否为空或者length等于0，如果是则调用resize方法进行初始化
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 2.通过hash值计算索引位置，将该索引位置的头节点赋值给p，如果p为空则直接在该索引位置新增一个节点即可
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        // table表该索引位置不为空，则进行查找
        Node<K,V> e; K k;
        // 3.判断p节点的key和hash值是否跟传入的相等，如果相等, 则p节点即为要查找的目标节点，将p节点赋值给e节点
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 4.判断p节点是否为TreeNode, 如果是则调用红黑树的putTreeVal方法查找目标节点
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            // 5.走到这代表p节点为普通链表节点，则调用普通的链表方法进行查找，使用binCount统计链表的节点数
            for (int binCount = 0; ; ++binCount) {
                // 6.如果p的next节点为空时，则代表找不到目标节点，则新增一个节点并插入链表尾部
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // 7.校验节点数是否超过8个，如果超过则调用treeifyBin方法将链表节点转为红黑树节点，
                    // 减一是因为循环是从p节点的下一个节点开始的
                    if (binCount >= TREEIFY_THRESHOLD - 1)
                        treeifyBin(tab, hash);
                    break;
                }
                // 8.如果e节点存在hash值和key值都与传入的相同，则e节点即为目标节点，跳出循环
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;  // 将p指向下一个节点
            }
        }
        // 9.如果e节点不为空，则代表目标节点存在，使用传入的value覆盖该节点的value，并返回oldValue
        if (e != null) {
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e); // 用于LinkedHashMap
            return oldValue;
        }
    }
    ++modCount;
    // 10.如果插入节点后节点数超过阈值，则调用resize方法进行扩容
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);  // 用于LinkedHashMap
    return null;
}
```



# ConcurrentHashMap

> ConcurrentHashMap源码解析
>
> http://www.eiletxie.cn/2019/12/27/ConcurrentHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/
>
> Java8 ConcurrentHashMap 源码解析

> https://ld246.com/article/1548220865009
>
> 关于jdk1.8中ConcurrentHashMap的方方面面
>
> https://blog.csdn.net/tp7309/article/details/76532366



## 1、存储结构

#### 1.1 JDK 1.7 的存储结构

> 在 JDK 1.7 ，ConcurrentHashMap 通过对 Segment 的分段加锁实现线程安全。一个 Segment 里面就是 HashMap 的存储结构，可以扩容。**Segment 的数据量初始化以后不可以更改**，默认值 16，因此默认支持 16 个线程同时操作 ConcurrentHashMap。

![img](https://gitee.com/ylooq/image-repository/raw/master/images/image-20200405151029416.png)

#### 1.2 JDK 1.8 的存储结构

> JDK 1.8 之后，存储结构变化比较大，跟 HashMap 类似。**红黑树节点小于某个数(默认值 6) 又会转换为链表。**

![image-20200809221531416](https://gitee.com/ylooq/image-repository/raw/master/images/image-20200809221531416.png)



## Unsafe 里的 CAS 操作相关

> 首先介绍的 cas，主要是因为 8 的 ConcurrentHashMap 主要用的就是 cas。
>
> CAS(compare-and-swap 比较交换)操作。CAS 是一种低级别的、细粒度的技术,它允许多个线程更新一个内存位置,同时能够检测其他线程的冲突并进行恢复。它是许多高性能并发算法的基础。 CAS 是一些 CPU 直接支持的指令，操作都封装在 java 不公开的类库中,sun.misc.Unsafe。此类包含了对原子操作的封装,具体用本地代码实现。本地的 C 代码直接利用到了硬件上的原子操作，在 Java 中无锁操作 CAS 基于以下 3 个方法实现。



```java
//第一个参数o为给定对象，offset为对象内存的偏移量，通过这个偏移量迅速定位字段并设置或获取该字段的值，
//expected表示期望值，x表示要设置的值，下面3个方法都通过CAS原子指令执行操作。
public final native boolean compareAndSwapObject(Object o, long offset,Object expected, Object x);                                                                                                  
 
public final native boolean compareAndSwapInt(Object o, long offset,int expected,int x);
 
public final native boolean compareAndSwapLong(Object o, long offset,long expected,long x);

```



## 主要属性

> - DEFAULT_CAPACITY：ConcurrentHashMap的默认大小是16
> - LOAD_FACTOR：负载因子。ConcurrentHashMap在超过16 * 0.75之后，就需要扩容了。
> - TREEIFY_THRESHOLD：发生哈希冲突的链表长度如果大于等于8，就会转变为红黑树
> - UNTREEIFY_THRESHOLD：发生哈希冲突的红黑树，在小于等于6个元素之后，就会回退成链表
> - MIN_TREEIFY_CAPACITY：当ConcurrentHashMap的大小大于等于64的时候，才允许将冲突的链表转为红黑树
> - Node<K,V>[] table 保存哈希桶的数组，大小是2的倍数
> - CounterCell[] counterCells：保存各个桶大小

```json
// node数组最大容量：2^30=1073741824
private static final int MAXIMUM_CAPACITY = 1 << 30;
// 默认初始值，必须是2的幕数
private static final int DEFAULT_CAPACITY = 16;
//数组可能最大值，需要与toArray（）相关方法关联
static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
//并发级别，遗留下来的，为兼容以前的版本
private static final int DEFAULT_CONCURRENCY_LEVEL = 16;
// 负载因子
private static final float LOAD_FACTOR = 0.75f;
// 链表转红黑树阀值,> 8 链表转换为红黑树
static final int TREEIFY_THRESHOLD = 8;
//树转链表阀值，小于等于6（tranfer时，lc、hc=0两个计数器分别++记录原bin、新binTreeNode数量，<=UNTREEIFY_THRESHOLD 则untreeify(lo)）
static final int UNTREEIFY_THRESHOLD = 6;
static final int MIN_TREEIFY_CAPACITY = 64;
private static final int MIN_TRANSFER_STRIDE = 16;
private static int RESIZE_STAMP_BITS = 16;
// 2^15-1，help resize的最大线程数
private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1;
// 32-16=16，sizeCtl中记录size大小的偏移量
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;
// forwarding nodes的hash值
static final int MOVED     = -1;
// 树根节点的hash值
static final int TREEBIN   = -2;
// ReservationNode的hash值
static final int RESERVED  = -3;
// 可用处理器数量
static final int NCPU = Runtime.getRuntime().availableProcessors();
//存放node的数组
transient volatile Node<K,V>[] table;
/*控制标识符，用来控制table的初始化和扩容的操作，不同的值有不同的含义
 *当为负数时：-1代表正在初始化，-N代表有N-1个线程正在 进行扩容
 *当为0时：代表当时的table还没有被初始化
 *当为正数时：表示初始化或者下一次进行扩容的大小
 */
private transient volatile int sizeCtl;
//线程迁移 bin 的起始位置，CAS(transferIndex)成功者可迁移 transferIndex 前置 stride 个 bin（见 transfer）
private transient volatile int transferIndex;
//该属性保存着整个哈希表中存储的所有的结点的个数总和，有点类似于 HashMap 的 size 属性。
private transient volatile long baseCount;
```

## 重要的内部类

#### Node

```java
static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        volatile V val; // Java8增加volatile，保证可见性
        volatile Node<K,V> next;
 
        Node(inthash, K key, V val, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.val = val;
            this.next = next;
        }
 
        public final K getKey()       { return key; }
        public final V getValue()     { return val; }
        // HashMap调用Objects.hashCode()，最终也是调用Object.hashCode()；效果一样
        public final int hashCode()   { returnkey.hashCode() ^ val.hashCode(); }
        public final String toString(){ returnkey + "=" + val; }
        public final V setValue(V value) { // 不允许修改value值，HashMap允许
            throw new UnsupportedOperationException();
        }
        // HashMap使用if (o == this)，且嵌套if；concurrent使用&&
        public final boolean equals(Object o) {
            Object k, v, u; Map.Entry<?,?> e;
            return ((oinstanceof Map.Entry) &&
                    (k = (e = (Map.Entry<?,?>)o).getKey()) != null &&
                    (v = e.getValue()) != null &&
                    (k == key || k.equals(key)) &&
                    (v == (u = val) || v.equals(u)));
        }
 
        /**
         * Virtualized support for map.get(); overridden in subclasses.
         */
        Node<K,V> find(inth, Object k) { // 增加find方法辅助get方法
            Node<K,V> e = this;
            if (k != null) {
                do {
                    K ek;
                    if (e.hash == h &&
                        ((ek = e.key) == k || (ek != null && k.equals(ek))))
                        returne;
                } while ((e = e.next) != null);
            }
            return null;
        }
    }

作者：yangyujiao
链接：https://ld246.com/article/1548220865009
来源：链滴
协议：CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0/
```

> 这个 Node 内部类与 HashMap 中定义的 Node 类很相似，但是有一些差别
>
> 它对 value 和 next 属性设置了 volatile 同步锁
>
> 它不允许调用 setValue 方法直接改变 Node 的 value 域
>
> 它增加了 find 方法辅助 map.get()方法

#### TreeNode

```java
// Nodes for use in TreeBins，链表>8，才可能转为TreeNode.
// HashMap的TreeNode继承至LinkedHashMap.Entry；而这里继承至自己实现的Node，将带有next指针，便于treebin访问。
    static final class TreeNode<K,V> extends Node<K,V> { 
        TreeNode<K,V> parent;  // red-black tree links
        TreeNode<K,V> left;
        TreeNode<K,V> right;
        TreeNode<K,V> prev;    // needed to unlink next upon deletion
        boolean red;
 
        TreeNode(inthash, K key, V val, Node<K,V> next,
                 TreeNode<K,V> parent) {
            super(hash, key, val, next);
            this.parent = parent;
        }
 
        Node<K,V> find(inth, Object k) {
            return findTreeNode(h, k, null);
        }
 
        /**
         * Returns the TreeNode (or null if not found) for the given key
         * starting at given root.
         */ // 查找hash为h，key为k的节点
        final TreeNode<K,V> findTreeNode(int h, Object k, Class<?> kc) {
            if (k != null) { // 比HMap增加判空
                TreeNode<K,V> p = this;
                do  {
                    intph, dir; K pk; TreeNode<K,V> q;
                    TreeNode<K,V> pl = p.left, pr = p.right;
                    if ((ph = p.hash) > h)
                        p = pl;
                    elseif (ph < h)
                        p = pr;
                    elseif ((pk = p.key) == k || (pk != null && k.equals(pk)))
                        returnp;
                    elseif (pl == null)
                        p = pr;
                    elseif (pr == null)
                        p = pl;
                    elseif ((kc != null ||
                              (kc = comparableClassFor(k)) != null) &&
                             (dir = compareComparables(kc, k, pk)) != 0)
                        p = (dir < 0) ? pl : pr;
                    elseif ((q = pr.findTreeNode(h, k, kc)) != null)
                        returnq;
                    else
                        p = pl;
                } while (p != null);
            }
            return null;
        }
    }


作者：yangyujiao
链接：https://ld246.com/article/1548220865009
来源：链滴
协议：CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0/
```

> 树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为 TreeNode。但是与 HashMap 不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成 TreeNode 放在 TreeBin 对象中，由 TreeBin 完成对红黑树的包装。而且 TreeNode 在 ConcurrentHashMap 集成自 Node 类，而并非 HashMap 中的集成自 LinkedHashMap.Entry<K,V> 类，也就是说 TreeNode 带有 next 指针，这样做的目的是方便基于 TreeBin 的访问



#### TreeBin

```java
TreeBin(TreeNode<K,V> b) {
    super(TREEBIN, null, null, null);//hash值为常量TREEBIN=-2,表示roots of trees
    this.first = b;
    TreeNode<K,V> r = null;
    for (TreeNode<K,V> x = b, next; x != null; x = next) {
        next = (TreeNode<K,V>)x.next;
        x.left = x.right = null;
        if (r == null) {
            x.parent = null;
            x.red = false;
            r = x;
        }
        else {
            K k = x.key;
            inth = x.hash;
            Class<?> kc = null;
            for (TreeNode<K,V> p = r;;) {
                intdir, ph;
                K pk = p.key;
                if ((ph = p.hash) > h)
                    dir = -1;
                elseif (ph < h)
                    dir = 1;
                elseif ((kc == null &&
                          (kc = comparableClassFor(k)) == null) ||
                         (dir = compareComparables(kc, k, pk)) == 0)
                    dir = tieBreakOrder(k, pk);
                    TreeNode<K,V> xp = p;
                if ((p = (dir <= 0) ? p.left : p.right) == null) {
                    x.parent = xp;
                    if (dir <= 0)
                        xp.left = x;
                    else
                        xp.right = x;
                    r = balanceInsertion(r, x);
                    break;
                }
            }
        }
    }
    this.root = r;
    assert checkInvariants(root);
}

作者：yangyujiao
链接：https://ld246.com/article/1548220865009
来源：链滴
协议：CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0/
```

> TreeBin 用于封装维护 TreeNode，包含 putTreeVal、lookRoot、UNlookRoot、remove、balanceInsetion、balanceDeletion 等方法。
>
> 这里只分析其构造函数，可以看到在构造 TreeBin 节点时，仅仅指定了它的 hash 值为 TREEBIN 常量，这也就是个标识为。同时也看到我们熟悉的红黑树构造方法
>
> 当链表转树时，用于封装 TreeNode，也就是说，ConcurrentHashMap 的红黑树存放的是 TreeBin，而不是 treeNode。

## 3个核心tabAt方法

`ConcurrentHashMap`在操作`Node`数据中的节点时，为了保证线程安全，定义了以下三个原子操作，使用unsafe机制实现。

```java
 @SuppressWarnings("unchecked")
    //获得在i位置上的Node节点
    static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
        return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
    }
	//利用CAS算法设置i位置上的Node节点。之所以能实现并发是因为他指定了原来这个节点的值是多少
	//在CAS算法中，会比较内存中的值与你指定的这个值是否相等，如果相等才接受你的修改，否则拒绝你的修改
	//因为当前线程中的值已经不是最新的值，你的修改很可能会覆盖掉其他线程修改的结果。这一点与乐观锁，SVN的思想是比较类似的
    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,
                                        Node<K,V> c, Node<K,V> v) {
        return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
    }
	//利用volatile方法设置节点位置的值
    static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
        U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
    }


作者：yangyujiao
链接：https://ld246.com/article/1548220865009
来源：链滴
协议：CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0/
```

第一个方法从主内存中读数据而不是工作内存，第二个方法CAS设置节点，第三个方法将节点的值直接更新到主内存。



## 重要的参数 SizeCtl

```java
/* 表初始化和大小调整控制。 如果为负，则表正在初始化或调整大小：-1用于初始化， else-（1 +活动的调整大小   
 *线程数）。
 * 除此以外，当table为null时，保留要使用的初始表大小创建，或默认为0。  
 * 初始化后，记录下一个要调整表大小的元素计数值。 
 * 注意： 也就是说 大于0时 代表已经初始化了，记录的是下一次的扩容后的阈值 
 */ 
 private transient volatile int sizeCtl;
```

> - -1，表示有线程正在进行初始化操作
> - (1 + nThreads)，表示有n个线程正在一起扩容
> - 0，默认值，后续在真正初始化的时候使用默认容量
> - 大于0，初始化或扩容完成后下一次的扩容门槛

## initTable方法

> 主要就是初始化一个合适大小的数组，然后会设置 sizeCtl。
>
> 初始化方法中的并发问题是通过对 sizeCtl 进行一个 CAS 操作来控制的。
>
> 该方法的核心思想就是，只允许一个线程对表进行初始化，如果不巧有其他线程进来了，那么会让其他线程交出 CPU 等待下次系统调度。这样，保证了表同时只会被一个线程初始化。

```java
/ 使用sizeCtl中记录的大小初始化表。
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        // 从上面sizeCtl 解释可知，当 sizeCtl < 0 时，证明其他线程已在初始化数组，所以 thread.yield 让出当前线程执行权，保证只有一个线程在初始化数组
        if ((sc = sizeCtl) < 0)
            Thread.yield(); 
        // U是unSafe类,这里再判断一次如果 SIZECTL为0，证明无其他线程初始化tab, 设置 SIZECTL--,禁止其他线程修改tab大小，如果SIZECTL<0,则进行下次循环判断
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            //如果把sizeCtl原子更新为-1成功，则当前线程进入初始化
                //如果原子更新失败则说明有其它线程先一步进入初始化了，则进入下一次循环
                //如果下一次循环时还没初始化完毕，则sizeCtl<0进入上面if的逻辑让出CPU
                //如果下一次循环更新完毕了，则table.length!=0，退出循环
            try {
                // 这里为什么还要判断一次不太明白，毕竟前面CAS已经做了判断，此时应该没有其他线程可以操作，除非是扩容时有其他操作，咋们待会再看
                ////再次检查table是否为空，防止ABA问题
                if ((tab = table) == null || tab.length == 0) {
                    // 注意此时sc >= 0,只有 sc = 0的时候才等于DEFAULT_CAPACITY 16，实际上当sc > 0时，代表此时数组是已经初始化过的，应该是不会进入initTable该方法了
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    // 如果 之前sc =0，则此时 n - 0.25n = 0.75n,也就是阈值 threshold，这种做法就是 取当前数组大小* 0.75 //设置sc为数组长度的0.75倍
                        //n - (n >>> 2) = n - n/4 = 0.75n
                        //可见这里装载因子和扩容门槛都是写死了的 这也正是没有threshold和loadFactor属性的原因
                    sc = n - (n >>> 2);
                }
            } finally {
                // sizeCtl记录了下一次调整数组大小的阈值
                //把sc赋值给sizeCtl，这时存储的是扩容门槛
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

>  我们可以看到， ConcurrentHashMap中的数组初始化方法 initTable使用了 CAS来做了 乐观锁同步判断，判断的标志是 sizeCtl,如果现在还对 sizeCtl 迷糊的同学建议再往上重新看一下 sizeCtl的定义，
>
> （1）使用CAS锁控制只有一个线程初始化桶数组；
>
> （2）sizeCtl在初始化后存储的是扩容门槛；
>
> （3）扩容门槛写死的是桶数组大小的0.75倍，桶数组大小即map的容量，也就是最多存储多少个元素。
>
> sizeCtl : volatile修饰，判断是否有线程在修改数组大小，为正数时，代表下一次的扩容的阈值
>
> 还记得put方法中当头节点的hash = MOVED即-1时，帮助转移吗？



## addCount 方法

> 因为concurrentHashMap是在并发情况下使用的，那么在计算size的同时也可能有别的线程在插入数据或者删除数据引起size的改变。

```java
//这里可以看到size的计算是baseCount变量和counterCells的CountterCell的数组中的值的总和
private final void addCount(long x, int check) {
    	//check就是结点数量，有新元素加入成功才检查是否要扩容。
        CounterCell[] as; long b, s;
        // 如果as不为null（存在并发），或者CAS更新baseCount失败
        if ((as = counterCells) != null ||
            !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
            // 通过as来计数
            CounterCell a; long v; int m;
            boolean uncontended = true;
            // 如果 as 是空（还不是并发）或者 (ss 中随机取余一个数组位置为空 或者 ss 这个位置的变量失败）
            // 说明通过as计数失败，调用fullAddCount
            if (as == null || (m = as.length - 1) < 0 ||
                (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
                !(uncontended =
                  U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
                fullAddCount(x, uncontended);
                return;
            }
            if (check <= 1)
                return;
            // 统计当前的总大小
            s = sumCount();
        }
        if (check >= 0) {
            Node<K,V>[] tab, nt; int n, sc;
            // 检查扩容条件：
        // 1. 是否达到阀值: s >= sizeCtl 
        // 2. 是否可以扩容: tab != null && tab 当前的长度小于 1 << 30
         //新容量大于当前扩容阈值并且小于最大扩容值才扩容，如果tab=null说明正在初始化，死循环等待初始化完成。
        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
                   (n = tab.length) < MAXIMUM_CAPACITY) {
                // 根据当前桶的数量生成一个标志位
                int rs = resizeStamp(n);
              //sc<0表示已经有线程在进行扩容工作
                if (sc < 0) {
                    // 检查当前扩容的进展:
                // 1. 如果 sc 的低 16 位不等于标识位（ sizeCtl 变化了，说明容器状态已经变化），退出
                // 2. 如果 sc == 标识位 + 1 （通过下面代码可知，刚开始扩容时， sc = rs + 2，如果 sc = rs + 1，说明已经没有线程在扩容），退出
                // 3. 如果 sc == 标识符 + 65535，参与扩容的线程已经达到最大数量，当前线程不再参与，退出
                // 4. 如果 nextTable == null 说明扩容结束（nextTable 在扩容中起中转作用，所有的元素会被限移到 nextTable 中，最后让 tab = nextTable，nextTable == null 来完成扩容），退出
                // 5. transferIndex <= 0 说明没有桶还需要迁移了（transferIndex 用于标识当前迁移到哪个桶了，小于等于 0 说明已经迁移到最后一个桶或者已经迁移完成，迁移的顺序是从最后一个桶开始），退出。
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                        sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                        transferIndex <= 0)
                        break;
                    // 如果迁移还是进行，当前线程尝试参与扩容
                    if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                        transfer(tab, nt);
                }
                // 如果当前不在扩容中，则发起一个新的扩容
                else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                             (rs << RESIZE_STAMP_SHIFT) + 2))
                    transfer(tab, null);
                s = sumCount();
            }
        }
    }

private final void fullAddCount(long x, boolean wasUncontended) {
    int h;
    //生成随机数，如果为0代表没有生成器没有初始化，进行初始化
    if ((h = ThreadLocalRandom.getProbe()) == 0) {
        ThreadLocalRandom.localInit();      // force initialization
        h = ThreadLocalRandom.getProbe();
        wasUncontended = true;
    }
    boolean collide = false;                // True if last slot nonempty
    
    //自旋，保证数量的变化一定能记录到counterCell数组中
    for (;;) {
        CounterCell[] as; CounterCell a; int n; long v;
        if ((as = counterCells) != null && (n = as.length) > 0) {
            //通过散列前面的随机数计算对应在counterCell中的下标
            //如果该位置为null则实例化一个counterCell对象，x作为参数记录下元素变化数量
            if ((a = as[(n - 1) & h]) == null) {
                if (cellsBusy == 0) {           
                    CounterCell r = new CounterCell(x);
                    //UnSafe修改cellsBusy的值，cellsBusy可以理解为一个锁，谁修改成功了谁就可以进行下面的数组元素赋值操作。
                    if (cellsBusy == 0 &&
                        U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                        boolean created = false;
                        try {               // Recheck under lock
                            CounterCell[] rs; int m, j;
                            if ((rs = counterCells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {
                                rs[j] = r;
                                created = true;
                            }
                        } finally {
                            //完成赋值后改回0，表示锁释放了。
                            cellsBusy = 0;
                        }
                        if (created)
                            break;
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
            else if (!wasUncontended)       // CAS already known to fail
                wasUncontended = true;      // Continue after rehash
            //数组位置如果不为null，则直接cas给这个counterCell加上修改元素的数量
            else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))
                break;
            else if (counterCells != as || n >= NCPU)
                collide = false;            // At max size or stale
            else if (!collide)
                collide = true;
            //如果上面cas修改值失败了，就表示出现了冲突。那么就获取cellbusy这个锁，将countercell数组扩容为原来的二倍
            else if (cellsBusy == 0 &&
                     U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                try {
                    //扩容为二倍，将原来的值拿回来。
                    if (counterCells == as) {// Expand table unless stale
                        CounterCell[] rs = new CounterCell[n << 1];
                        for (int i = 0; i < n; ++i)
                            rs[i] = as[i];
                        counterCells = rs;
                    }
                } finally {
                    //改回0释放锁
                    cellsBusy = 0;
                }
                collide = false;
                continue;                   // Retry with expanded table
            }
            //重新生成随机数，用于下次循环
            h = ThreadLocalRandom.advanceProbe(h);
        }
        //如果数组为空，则进行counterCell数组的初始化
        else if (cellsBusy == 0 && counterCells == as &&
                 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
            boolean init = false;
            try {                           // Initialize table
                if (counterCells == as) {
                    CounterCell[] rs = new CounterCell[2];
                    rs[h & 1] = new CounterCell(x);
                    counterCells = rs;
                    init = true;
                }
            } finally {
                cellsBusy = 0;
            }
            if (init)
                break;
        }
        else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x))
            break;                          // Fall back on using base
    }
}
```

#### resizeStamp()

在上面的代码中首先有调用到这样的一个方法。

```java
/**
 * The number of bits used for generation stamp in sizeCtl.
 * Must be at least 6 for 32bit arrays.
*/
private static int RESIZE_STAMP_BITS = 16;

/**
 * The bit shift for recording size stamp in sizeCtl.
 */
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

static final int resizeStamp(int n) {
        return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));
}


```

> Integer.numberOfLeadingZeros(n)用于计算n转换成二进制后前面有几个0。这个有什么作用呢？
> 首先ConcurrentHashMap的容量必定是2的幂次方，所以不同的容量n前面0的个数必然不同，这样可以保证是在原容量为n的情况下进行扩容。
> (1 << (RESIZE_STAMP_BITS - 1)即是1<<15，表示为二进制即是高16位为0，第16位为1：
>
> ```json
> 0000 0000 0000 0000 1000 0000 0000 0000
> ```
>
> 所以resizeStamp()的返回值(简称为rs) 高16位置0，第16位为1，低15位存放当前容量n扩容标识，用于表示是对n的扩容。
> rs与RESIZE_STAMP_SHIFT配合可以求出新的sizeCtl的值，分情况如下：
>
> sc >= 0
> 表示没有线程在扩容，使用CAS将sizeCtl的值改为(rs << RESIZE_STAMP_SHIFT) + 2)。
> sc < 0
> 已经有线程在扩容，将sizeCtl+1并调用transfer()让当前线程参与扩容。
> rs即resizeStamp(n)，如当前容量为8时sc(sizeCtl)的计算过程如下：
>
> ```json
> //容量n=8
> 0000 0000 0000 0000 0000 0000 0000 1000
> //Integer.numberOfLeadingZeros(8)=28，二进制表示如下：
> 0000 0000 0000 0000 0000 0000 0001 1100
> //(1 << (RESIZE_STAMP_BITS - 1)
> 0000 0000 0000 0000 1000 0000 0000 0000
> //rs
> 0000 0000 0000 0000 1000 0000 0001 1100
> //temp = rs << RESIZE_STAMP_SHIFT，即 temp = rs << 16，左移16后temp最高位为1，所以temp成了一个负数。
> 1000 0000 0001 1100 0000 0000 0000 0000
> //第一个线程要扩容时，sc = (rs << RESIZE_STAMP_SHIFT) + 2)
> 1000 0000 0001 1100 0000 0000 0000 0010
> 
> ```
>
> 那么在扩容时sizeCtl值的意义便如下图所示：
>
> | 高15位        | 低16位           |
> | ------------- | ---------------- |
> | 容量n扩容标识 | 并行扩容线程数+1 |



#### 总结

> size的计算是通过baseCount的值和counterCell数组中所有的值计算一个总和。
> 在put的过程中，调用了addCount方法，首先是修改baseCount的值，一旦发生竞争某个线程的baseCount修改失败，则会生成随机数通过散列获取countercell数组中的一个并修改值，如果失败就会通过自旋设置countercell的值直到成功为止，自旋内部如果还是竞争就会将countercell扩容为二倍，重新生成随机数进行尝试。
> 我认为countercell就是用来记录并发修改baseCount失败的值的，之所以在自旋修改countercell时候再失败会扩容也是为了减少线程冲突的概率，从而提升代码运行的速度，使用空间换时间。



## put方法

```java
public V put(K key, V value) {
    return putVal(key, value, false);
}

final V putVal(K key, V value, boolean onlyIfAbsent) {
    // ConcurrentHashMap 中 key value不允许为null
    if (key == null || value == null) throw new NullPointerException();
    //进行hash重新运算 (h ^ (h >>> 16)) & 0x7fffffff，官方解释 这种做法使得位扩散更合理，碰撞分布更均匀
    // 这个spread(hash)下来，保留了高16位，低16位进行了重新计算，然后又& HASHBIT使得最高位为0，其他位不变
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // 当 tab为空,初始化table，该方法是做了线程同步CAS判断的，在下方有对initTable详细的解释
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
        //tabAt方法调用的是Unsafe.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE) 可以直接获取指定内存的数据，保证了每次拿到的数组下标数据都是最新的
        // 注意此时已经 f = 数组下标下头节点， i 为 数组下标
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 这里cas判断数组下标下 i 的头节点 f是否为空并赋值
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        //此时说明 头节点f不为空 检查 f.hash == (MOVED为 -1) 内部移动，证明在扩容操作,待会看一下扩容时是否将节点hash重新赋值 MOVED标志位
        // 此时帮助还未转移的旧数组节点转移到新数组中
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        else { 
            // 当数组不在扩容时， 数组下标下有节点时，synchronize锁住该下标的头结点，f在上面已经赋值 数组对应下标的链表头节点
             // 如果这个桶不为空且不在迁移元素，则锁住这个桶（分段锁）
                // 并查找要插入的元素是否在这个桶中
                // 存在，则替换值（onlyIfAbsent=false）
                // 不存在，则插入到链表结尾或插入树中
            V oldVal = null;
             // 给当前数组下标的Node头结点加锁
            synchronized (f) {
                //再次检测第一个元素是否有变化，如果有变化则进入下一次循环，从头来过
                if (tabAt(tab, i) == f) {
                       //如果第一个元素的hash值大于等于0（说明不是在迁移，也不是树）
                        //那就是桶中的元素使用的是链表方式存储
                    if (fh >= 0) { // fh >=0 意味着 不在扩容 MOVED - 1，也不是红黑树 TREEBIN -2
                        binCount = 1;
                        // 在遍历链表时 ++bitCount，所以 bitCount代表链表的长度
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                   //如果找到了这个元素，则赋值了新值（onlyIfAbsent=false）
                                    //并退出循环
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                //如果到链表尾部还没有找到元素
                                    //就把它插入到链表结尾并退出循环
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    // 判断节点是红黑树时，进行红黑树的插入操作
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            // 这一步做链表长度的判断，当>= 8时转换成红黑树
            //如果binCount不为0，说明成功插入了元素或者寻找到了元素
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // 对当前容量大小进行检查，如果超过了阈值threshold（数组大小* 负载因子）就需要扩容
    // //成功插入元素，元素个数加1（是否要扩容在这个里面）
    addCount(1L, binCount);
    return null;
}
```



```java
public V put(K key, V value) {
  return putVal(key, value, false);
}
```



## transfer扩容方法

> 这是ConcurrentHashMap扩容操作的核心，这个方法相当的长而且非常复杂，因为它支持多线程并发进行扩容操作，并且没有用锁。

#### **演示扩容过程**

假设当前扩容前oldCap即oldTab的长度为2，扩容后newCap即newTab的长度为4。如下图看扩容过程，橘色的代表迁移后索引位依然是oldIndex，绿色代表扩容后索引位为oldIndex + oldCap。

![img](https://img2018.cnblogs.com/i-beta/1635748/202001/1635748-20200113180828655-1406714067.png)

上述代码段1迭代找到了lastRun即指向node（11），代码段2将lastRun赋值给hn。代码段3执行过程如下

> ```java
> 1，将node(1)拼接到ln
> 2，将node(3)拼接到hn，此时注意，hn已经lastRun指向的节点node(11)，此时hn=3—>11—>15—>19—>null
> 3，处理node(5)拼接到ln
> 4，处理...
> ```

![img](https://hyc-pic.oss-cn-hangzhou.aliyuncs.com/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pPS0VLQUk=,size_16,color_FFFFFF,t_70-20210318151704967.png)

#### 步骤

> 扩容操作分为两个步骤：
>
> 1. 构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。这个单线程的保证是通过RESIZE_STAMP_SHIFT这个常量经过一次运算来保证的。
> 2. 将原来table中的元素复制到nextTable中，这里允许多线程进行操作。
>
> 方法开始给`stride`变量赋值，先判断CPU的核心数，如果是单核，直接将表长度`n`赋值给`stride`，表示单核需要承担`rehash`所有桶的任务；如果是多核的，让表长度除8（为什么要除8？），然后再除核心数，让每个核心需要处理的桶一样多。如果平均分完后，每个核心分配的桶数量小于16，那么就默认为16。也就是说：
>
> 1. 通过 计算CPU核心数和旧哈希表的长度得到每个核心需要负责迁移多少个桶，每个核心负责的桶数是平均的。
> 2. 一个核心至少负责16个桶的任务。
> 3. **许多博客将核心数和线程数弄混了，虽然由于此操作时单线程的，一个核心对应一个线程，但是概念不能混淆，否则下面的多线程并发迁移就理解不了了。**

```java
int n = tab.length, stride;
if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
  stride = MIN_TRANSFER_STRIDE; // subdivide range
```

#### 并发操作的机制

> 原数组长度为 n，所以我们有 n 个迁移任务，让每个线程每次负责一个小任务是最简单的，每做完一个任务再检测是否有其他没做完的任务，帮助迁移就可以了，而 Doug Lea 使用了一个 stride，简单理解就是步长，每个线程每次负责迁移其中的一部分，如每次迁移 16 个小任务。所以，我们就需要一个全局的调度者来安排哪个线程执行哪几个任务，这个就是属性 transferIndex 的作用。
>
> 第一个发起数据迁移的线程会将 **transferIndex** 指向原数组**最后的位置**，然后从后往前的 stride 个任务属于第一个线程，然后将 transferIndex 指向新的位置，再往前的 stride 个任务属于第二个线程，依此类推。当然，这里说的第二个线程不是真的一定指代了第二个线程，也可以是同一个线程，这个读者应该能理解吧。其实就是将一个大的迁移任务分为了一个个任务包。
>
> ConcurrentHashMap 无锁多线程扩容，减少扩容时的时间消耗。
>  transfer 扩容操作：单线程构建两倍容量的 nextTable；允许多线程复制原 table 元素到 nextTable。
>
> 1. 为每个内核均分任务，并保证其不小于 16；
> 2. 若 nextTab 为 null，则初始化其为原 table 的 2 倍；
> 3. 死循环遍历，直到 finishing。
>
> - 节点为空，则插入 ForwardingNode；
> - 链表节点（fh>=0），分别插入 nextTable 的 i 和 i+n 的位置；
> - TreeBin 节点（fh<0），判断是否需要 untreefi，分别插入 nextTable 的 i 和 i+n 的位置；
> - finishing 时，nextTab 赋给 table，更新 sizeCtl 为新容量的 0.75 倍 ，完成扩容。
>
> 
>
> 这个方法的核心在于 sizeCtl 值的操作，首先将其设置为一个负数，然后执行 transfer(tab, null)，再下一个循环将 sizeCtl 加 1，并执行 transfer(tab, nt)，之后可能是继续 sizeCtl 加 1，并执行 transfer(tab, nt)。
>
> 所以，可能的操作就是执行 1 次 transfer(tab, null) + 多次 transfer(tab, nt)，这里怎么结束循环的需要看完 transfer 源码才清楚。
>
> **以上说的都是单线程，多线程又是如何实现的呢？**
>
> 遍历到 ForwardingNode 节点((fh = f.hash) == MOVED)，说明此节点被处理过了，直接跳过。这是控制并发扩容的核心。由于给节点上了锁，只允许当前线程完成此节点的操作，处理完毕后，将对应值设为 ForwardingNode（fwd），其他线程看到 forward，直接向后遍历。如此便完成了多线程的复制工作，也解决了线程安全问题。
>
> 

#### 哈希桶迁移中以及迁移后处理get和put方法

> - 还未被迁移到的`hash`桶正常进行`get`和`put`操作，因为没有遇到`ForwardingNode`。
> - 正在迁移的桶遇到了`get`请求， 通过`ForwardingNode`的`nextTable`字段转发到新的表上查询。
> - 正在迁移的桶遇到了`put`请求，在`rehash`时，链表头节点的哈希值会被设置为`MOVED`，写入线程会去协助`rehash`。

#### 源码解析

```java
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
    int n = tab.length, stride;
    // 当CPU核数大于1时，stride 等于 桶的数量/8 再除 CPU核数，不然就一个CPU处理所有桶
    //  MIN_TRANSFER_STRIDE 默认16,该值至少应为 DEFAULT_CAPACITY。
    // 这里我们分析一下 当CPU为8核时，stride为0 < MIN_TRANSFER_STRIDE  所以stride = 16
    // 从现有服务器的核数分析 这么基本就是让 stride为16，为什么？  
    // 这里的目的是让每个 CPU 处理的桶一样多，避免出现转移任务不均匀的现象，如果桶较少的话，默认一个 CPU（一个线程）处理 16 个桶
    // 所以我猜测这里是让每个线程处理16个下标对应的桶节点
     // stride 在单核下直接等于 n，多核模式下为 (n>>>3)/NCPU，最小值是 16
    // stride 可以理解为”步长“，有 n 个位置是需要进行迁移的，
    //   将这 n 个任务分为多个任务包，每个任务包有 stride 个任务
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
        // 如果 nextTab 为 null，先进行一次初始化
    //    前面我们说了，外围会保证第一个发起迁移的线程调用此方法时，参数 nextTab 为 null
    //       之后参与迁移的线程调用此方法时，nextTab 不会为 null
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings("unchecked") // 容量翻倍 n<<1
            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        // nextTable 是成员变量 、 更新 transferIndex 转移下标，就是原来tab的length
        nextTable = nextTab;
         // transferIndex 也是 ConcurrentHashMap 的属性，用于控制迁移的位置
        transferIndex = n;
    }
    int nextn = nextTab.length;
    //  创建一个 fwd 节点，用于占位。ForwardingNode 翻译过来就是正在被迁移的 Node原数组中位置 i 处的节点完成迁移工作后 就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了
    //    所以它其实相当于是一个标志。
    //新建一个ForwardingNode类型的节点，并把新桶数组存储在里面
    ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
    //  首次推进为 true，如果等于 true，说明需要再次推进一个下标（i--），反之，如果是 false，那么就不能推进下标，需要将当前的下标处理完毕才能继续推进
    boolean advance = true;
    // 确定数组扩容结束标志
    boolean finishing = false; // to ensure sweep before committing nextTab
    //   死循环,i 表示下标，bound 表示当前线程可以处理的当前桶区间最小下标 i 是位置索引，bound 是边界，注意是从后往前
    for (int i = 0, bound = 0;;) {
        Node<K,V> f; int fh;
        //  如果当前线程可以向后推进；这个循环就是控制 i 递减。同时，每个线程都会进入这里取得自己需要转移的桶的区间
        // advance 为 true 表示可以进行下一个位置的迁移了
        //   简单理解结局：i 指向了 transferIndex，bound 指向了 transferIndex-stride
            // i的值会从n-1依次递减 其中n是旧桶数组的大小，也就是说i从15开始一直减到1这样去迁移元素
        while (advance) {
            int nextIndex, nextBound;
              // 对 i 减一，判断是否大于等于 bound （正常情况下，如果大于 bound 不成立，说明该线程上次领取的任务已经完成了。那么，需要在下面继续领取任务）
            // 如果对 i 减一大于等于 bound（还需要继续做任务），或者完成了，修改推进状态为 false，不能推进了。任务成功后修改推进状态为 true。
            // 通常，第一次进入循环，i-- 这个判断会无法通过，从而走下面的 nextIndex 赋值操作（获取最新的转移下标）。
            //其余情况都是：如果可以推进，将 i 减一，然后修改成不可推进。如果 i 对应的桶处理成功了，改成可以推进。
             if (--i >= bound || finishing)
                advance = false;// 这里设置 false，是为了防止在没有成功处理一个桶的情况下却进行了推进
            // 这里的目的是：1. 当一个线程进入时，会选取最新的转移下标。2. 当一个线程处理完自己的区间时，如果还有剩余区间的没有别的线程处理。再次获取区间。
            // 这里 transferIndex 一旦小于等于 0，说明原数组的所有位置都有相应的线程去处理了
            else if ((nextIndex = transferIndex) <= 0) {
                // 如果小于等于0，说明没有区间了 ，i 改成 -1，推进状态变成 false，不再推进，表示，扩容结束了，当前线程可以退出了
                // 这个 -1 会在下面的 if 块里判断，从而进入完成状态判断
                i = -1;
                advance = false;// 这里设置 false，是为了防止在没有成功处理一个桶的情况下却进行了推进
            }// CAS 修改 transferIndex，即 length - 区间值，留下剩余的区间值供后面的线程使用
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex > stride ?
                                   nextIndex - stride : 0))) {//transferIndex减去已分配出去的桶。
                  //确定当前线程每次分配的待迁移桶的范围为[bound, nextIndex)
                bound = nextBound;// 这个值就是当前线程可以处理的最小当前区间最小下标
                i = nextIndex - 1; // 初次对i 赋值，这个就是当前线程可以处理的当前区间的最大下标
                advance = false; // 这里设置 false，是为了防止在没有成功处理一个桶的情况下却进行了推进，这样对导致漏掉某个桶。下面的 if (tabAt(tab, i) == f) 判断会出现这样的情况。
            }
        }
       // 注意，这里的n是原数组大小
       // 当i为负数，应该是代表扩容区间扫描完了
       // i >= n 代表到了 新数组的后半段区间
       // 这里 i + n >= nextn,nextn是新数组大小，从而推导出 i此时在后半段区间
         //当前线程自己的活已经做完或所有线程的活都已做完，第二与第三个条件应该是下面让"i = n"后，再次进入循环时要做的边界检查。
        if (i < 0 || i >= n || i + n >= nextn) {
            int sc;
            //如果全部迁移完成了，则替换旧桶数组 并设置下一次扩容门槛为新桶数组容量的0.75倍
            // 当转移结束，sizeCtl为 2n * 0.75 即下一次扩容大小，原数组正式替换成新扩容后的数组
            if (finishing) {
                nextTable = null;
                table = nextTab;
                sizeCtl = (n << 1) - (n >>> 1);
                return;
            }// 如果没完成扩容
          if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
              // 尝试将 sc -1. 表示这个线程结束帮助扩容了，将 sc 的低 16 位减一。 
              if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
              // 如果 sc - 2 不等于标识符左移 16 位。如果他们相等了，说明没有线程在帮助他们扩容了。也就是说，扩容结束了。 
              return;// 不相等，说明没结束，当前线程结束方法。 //扩容完成两边肯定相等
              finishing = advance = true;// 如果相等，扩容结束了，更新 finising 变量 
              //i重新赋值为n
                    // 这样会再重新遍历一次桶数组，看看是不是都迁移完成了
                    // 也就是第二次遍历都会走到下面的(fh = f.hash) == MOVED这个条件
              i = n; // 再次循环检查一下整张表 
          }

        } // 当数组对应下标节点为空时，填充为fwd占位标志，代表该节点不需要理会，可直接跳过，注意这里 f被赋值成下标首节点 
        //如果桶中无数据，直接放入ForwardingNode标记该桶已迁移
        else if ((f = tabAt(tab, i)) == null)
            //如果i处是ForwardingNode表示第i个桶已经有线程在负责迁移了。
            advance = casTabAt(tab, i, null, fwd);
        // 如果状态为 MOVED，代表有其他线程正在帮助该下标转移数据，推进标志advance，代表可替换到下一个节点
        else if ((fh = f.hash) == MOVED) 
              //如果桶中第一个元素的hash值为MOVED 说明它是ForwardingNode节点 也就是该桶已迁移
            advance = true; // already processed
        else {
            // 经过上述判断，确定了当前节点处于正常状态，加同步锁进行数据转移，f在上面判断赋值为当前下标的首节点
            synchronized (f) {
                 // 判断 i 下标处的桶节点是否和 f 相同
                 //再次判断当前桶第一个元素是否有修改 也就是可能其它线程先一步迁移了元素
                if (tabAt(tab, i) == f) {
                          //把一个链表分化成两个链表 规则是桶中各元素的hash与桶大小n进行与操作
                        //等于0的放到低位链表(low)中，不等于0的放到高位链表(high)中
                        //其中低位链表迁移到新桶中的位置相对旧桶不变 高位链表迁移到新桶中位置正好是其在旧桶的位置加n
                        //这也正是为什么扩容时容量在变成两倍的原因
                     Node<K,V> ln, hn;// low, height 高位桶，低位桶
                    // 如果 f 的 hash 值大于 0,这代表是正常的链表节点 。TreeBin 的 hash 是 -2
                    if (fh >= 0) {
                        // 对老长度进行与运算（第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0）
                         // 注意这里 n是2次幂，所以二进制编码中只有一个1，那么取于 length 只有 2 种结果，一种是 0，一种是1 
                          //第一个元素的hash值大于等于0 说明该桶中元素是以链表形式存储的 这里与HashMap迁移算法基本类似
                            //唯一不同的是多了一步寻找lastRun 这里的lastRun是提取出链表后面不用处理再特殊处理的子链表
                            //比如所有元素的hash值与桶大小n与操作后的值分别为 0 0 4 4 0 0 0 则最后面三个0对应的元素肯定还是在同一个桶中
                            //这时lastRun对应的就是倒数第三个节点
                        int runBit = fh & n;
                        Node<K,V> lastRun = f;
                        // 遍历链表节点
                        for (Node<K,V> p = f.next; p != null; p = p.next) {
                            int b = p.hash & n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        } // 当runBit为0，放置在低位桶中 ，这里如果看不明白，可以看一下我hashmap对于原桶中链表节点分散成两个链表的处理过程
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        } // 否则放置在高位桶
                        else {
                            hn = lastRun;
                            ln = null;
                        }}// 再次循环，生成两个链表，lastRun 作为停止条件，这样就是避免无谓的循环（lastRun 后面都是相同的取于结果）
                        for (Node<K,V> p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph & n) == 0)
                                ln = new Node<K,V>(ph, pk, pv, ln);
                            else
                                hn = new Node<K,V>(ph, pk, pv, hn);
                        }
                     //低位链表的位置不变
                        setTabAt(nextTab, i, ln);
                      //高位链表的位置是原位置加n
                        setTabAt(nextTab, i + n, hn);
                     //标记当前桶已迁移
                        setTabAt(tab, i, fwd);
                     //advance为true，返回上面进行--i操作
                        advance = true;
                    } // 当桶中头节点是红黑树
                    else if (f instanceof TreeBin) {
                        TreeBin<K,V> t = (TreeBin<K,V>)f;
                        // 这里的扩容和hashmap的链表resize扩容逻辑几乎一致 分配核心逻辑  hash & n
                        TreeNode<K,V> lo = null, loTail = null;
                        TreeNode<K,V> hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node<K,V> e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode<K,V> p = new TreeNode<K,V>
                                (h, e.key, e.val, null, null);
                            if ((h & n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }]
                        // 当下标的节点数小于等于 6,由红黑树转换为链表，不然创建一颗新的树
                        ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin<K,V>(lo) : t;
                        hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin<K,V>(hi) : t;
                        setTabAt(nextTab, i, ln);
                        setTabAt(nextTab, i + n, hn);
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}
```

##### 拆解源码

```java
while (advance) {
  int nextIndex, nextBound;
  if (--i >= bound || finishing)
    advance = false;
  else if ((nextIndex = transferIndex) <= 0) {
    i = -1;
    advance = false;
  }
  else if (U.compareAndSwapInt
           (this, TRANSFERINDEX, nextIndex,
            nextBound = (nextIndex > stride ?
                         nextIndex - stride : 0))) {
    bound = nextBound;
    i = nextIndex - 1;
    advance = false;
  }
}
```

> 在循环体中：首先开启一个`while`循环，使用CAS不断尝试为当前线程分配任务，直到分配成功或任务队列已经被全部分配完毕。如果当前线程已经被分配过bucket区域，那么会通过`--i`指向下一个待处理bucket然后退出该循环（哈希表从后往前的顺序分配）。
>
> 退出这个循环有3个机会：
>
> 1. `--i >= bound || finishing`成立一个，如果`--i>=bound`说明当前线程已经分配过`bucket`区域了，如果`finishing == true`，说明扩容已经完成了。
> 2. `nextIndex = transferIndex` <= 0，表示所有bucket已经被分配完毕了，因为`transferIndex<=0`，`transferIndex`代表着下一个被划分的索引。
> 3. CAS执行成功，说明成功为当前线程分配了`bucket`区域。
> 4. 上面都失败了，就循环重来吧。
>
> 这里可以举个例子解释一下具体是怎么划分的，以单核CPU、首次扩容（旧表长度为8）为例。当前`stride`等于旧哈希表长`n`，`transferIndex`首先被赋值为`n`了。接下来代码进入了上面的循环体中，首先会CAS竞争修改`transferIndex`值，如果当前的`nextIndex`仍旧等于`transferIndex`，那么CAS成功，将`transferIndex`的值设置为`nextBound`。`nextBound`的计算方式如下：
>
> ```java
> nextBound = (nextIndex > stride ? nextIndex - stride : 0)
> 
> ```
>
> 也就是说，当`nextIndex`小于等于`stride`时，将`transferIndex`设置为0。那么什么情况下，`nextIndex`（`transferIndex` == `nextIndex`）会大于`stride`？回顾上面的代码，只有当核心数大于1时，`stride`会比`transferIndex`小。当核心数等于1时，`stride`只可能大于等于`transferIndex`。所以`nextBound`在这个例子中必然等于0。
>
> CAS成功后，设置区间为`[0, n-1]`，即`[0,15]`，将这个区间划分给当前核心的一条扩容线程。



#### 总结

> （1）新桶数组大小是旧桶数组的两倍；
>
> （2）迁移元素先从靠后的桶开始；
>
> （3）迁移完成的桶在里面放置一ForwardingNode类型的元素，标记该桶迁移完成；
>
> （4）迁移时根据hash&n是否等于0把桶中元素分化成两个链表或树；
>
> （5）低位链表（树）存储在原来的位置；
>
> （6）高们链表（树）存储在原来的位置加n的位置；
>
> （7）迁移元素时会锁住当前桶，也是分段锁的思想；



## ForwardingNode 

> 开始之前，这里解释一下 ForwardingNode ，这是一个 静态内部类 static final class ForwardingNode<K,V> extends Node<K,V>
>
> 它HASH属性默认是 MOVED移动状态，也就是说这个节点默认是 MOVED移动状态的节点，可以用来做节点的状态比较判断,也可作为一个扩容扫描时下标跳跃的标志。

```java
// A node inserted at head of bins during transfer operations.连接两个table
// 并不是我们传统的包含key-value的节点，只是一个标志节点，并且指向nextTable，提供find方法而已。生命周期：仅存活于扩容操作且bin不为null时，一定会出现在每个bin的首位。
static final class ForwardingNode<K,V> extends Node<K,V> {
    //新表的引用
    final Node<K,V>[] nextTable;
    ForwardingNode(Node<K,V>[] tab) {
        super(MOVED, null, null, null); // 此节点hash=-1，key、value、next均为null
        this.nextTable = tab;
    }
 
    //进行get操作的线程若发现槽中的节点为ForwordingNode类型
    //说明该桶中所有结点已迁移完成，会调用ForwordingNode的find方法在新表中进行查找
    Node<K,V> find(int h, Object k) {
        // 查nextTable节点，outer避免深度递归
        outer: for (Node<K,V>[] tab = nextTable;;) {
         // n表示新表的长度
            Node<K,V> e; int n;
            if (k == null || tab == null || (n = tab.length) == 0 ||
                (e = tabAt(tab, (n - 1) & h)) == null)
                return null;
            for (;;) { // CAS算法多和死循环搭配！直到查到或null
                int eh; K ek;
                if ((eh = e.hash) == h &&
                    ((ek = e.key) == k || (ek != null && k.equals(ek))))
                    return e;
                if (eh < 0) {
                    if (e instanceof ForwardingNode) {
                        tab = ((ForwardingNode<K,V>)e).nextTable;
                        continue outer;
                    }
                    else
                        return e.find(h, k);
                }
                if ((e = e.next) == null)
                    return null;
            }
        }
    }
}


作者：yangyujiao
链接：https://ld246.com/article/1548220865009
来源：链滴
协议：CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0/
```

> 一个用于连接两个 table 的节点类。它包含一个 nextTable 指针，用于指向下一张表。而且这个节点的 key value next 指针全部为 null，它的 hash 值为-1. 这里面定义的 find 的方法是从 nextTable 里进行查询节点，而不是以自身为头节点进行查找





## helpTransfer



> 我们在 putVal 方法中遍历整个 hash 表的桶结点，如果遇到 hash 值等于 MOVED，说明已经有线程正在扩容 rehash 操作，整体上还未完成，不过我们要插入的桶的位置已经完成了所有节点的迁移。
>
> 由于检测到当前哈希表正在扩容，于是让当前线程去协助扩容。

```java
final Node<K,V>[] helpTransfer(Node<K,V>[] tab, Node<K,V> f) {
        Node<K,V>[] nextTab;
        int sc;
        //如果桶数组不为空，并且当前桶第一个元素为ForwardingNode类型，并且nextTab不为空
        //说明当前桶已经迁移完毕了，才去帮忙迁移其它桶的元素
        //扩容时会把旧桶的第一个元素置为ForwardingNode，并让其nextTab指向新桶数组
        if (tab != null && (f instanceof ForwardingNode) &&
            (nextTab = ((ForwardingNode<K,V>)f).nextTable) != null) {
            int rs = resizeStamp(tab.length);
            //sizeCtl<0，说明正在扩容
            while (nextTab == nextTable && table == tab &&
                   (sc = sizeCtl) < 0) {
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || transferIndex <= 0)
                    break;
                //扩容线程数加1
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
                    //当前线程帮忙迁移元素
                    transfer(tab, nextTab);
                    break;
                }
            }
            return nextTab;
        }
        return table;
    }
```

# LinkedHashMap

[源码阅读之LinkedHashMap（JDK8）](https://www.cnblogs.com/lostyears/p/9176558.html)

https://www.cnblogs.com/lostyears/p/9176558.html



## LinkedHashMap的底层存储结构图

![img](https://i0.wp.com/upload-images.jianshu.io/upload_images/5158008-d2b275862ba06cf2.png)

## 成员变量

区别于1.7中的成员变量标志位置只有一个header节点;
JDK1.8中有一个head和一个tail节点;

###### JDK1.7

```java
	/**
     * The head of the doubly linked list.
     */
    private transient Entry<K,V> header;

    /**
     * The iteration ordering method for this linked hash map: <tt>true</tt>
     * for access-order, <tt>false</tt> for insertion-order.
     *
     * @serial
     */
    private final boolean accessOrder;
```

###### JDK1.8

```java
private static final long serialVersionUID = 3801124242820219131L;

// 用于指向双向链表的头部, 双向链表头节点（最老）
transient LinkedHashMap.Entry<K,V> head;
//用于指向双向链表的尾部,双向列表尾节点（最新）
transient LinkedHashMap.Entry<K,V> tail;
/**
 * 用来指定LinkedHashMap的迭代顺序，
 * true则表示按照基于访问的顺序来排列，意思就是最近使用的entry，放在链表的最末尾
 * false则表示按照插入顺序来
 */ 
final boolean accessOrder;
```

## Entry

LinkedHashMap 1.8中的Entry和1.7中的区别不大,都是`Map.Entry<K,V>`的实现

![这里写图片描述](https://img-blog.csdn.net/20170512155609530?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanVzdGxvdmV5b3Vf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![在这里插入图片描述](https://images2017.cnblogs.com/blog/1256203/201711/1256203-20171105115353170-1563498238.png)

同样的:
Entry里面的属性：
**1、K key**
**2、V value**
**3、Entry<K, V> next**
**4、int hash**
5、Entry<K, V> before
6、Entry<K, V> after

其中前面四个，也就是红色部分是从HashMap.Entry中继承过来的；后面两个，也就是蓝色部分是LinkedHashMap独有的。不要搞错了next和before、After，next是用于维护HashMap指定table位置上连接的Entry的顺序的，before、After是用于维护Entry插入的先后顺序的。

1.8中LinkedHashMap结构如下图:
有head和tail节点;

![在这里插入图片描述](https://img-blog.csdn.net/20181007193101218?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoZWxsZXlMaXR0bGVoZXJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



## 添加元素





## 覆盖的方法

在HashMap中有三个模版方法，供子类来覆盖，在访问、插入、删除某个节点之后，进行一些特殊处理。

```java
    // Callbacks to allow LinkedHashMap post-actions
    void afterNodeAccess(Node<K,V> p) { }
    void afterNodeInsertion(boolean evict) { }
    void afterNodeRemoval(Node<K,V> p) { }
```



#### afterNodeAccess

会将当前被访问到的节点e，移动至内部的双向链表的尾部。

```java
void afterNodeAccess(Node<K,V> e) { // move node to last
        LinkedHashMap.Entry<K,V> last;//原尾节点
        //如果accessOrder 是true ，且原尾节点不等于e
        if (accessOrder && (last = tail) != e) {
            //节点e强转成双向链表节点p
            LinkedHashMap.Entry<K,V> p =
                (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
            //p现在是尾节点， 后置节点一定是null
            p.after = null;
            //如果p的前置节点是null，则p以前是头结点，所以更新现在的头结点是p的后置节点a
            if (b == null)
                head = a;
            else//否则更新p的前直接点b的后置节点为 a
                b.after = a;
            //如果p的后置节点不是null，则更新后置节点a的前置节点为b
            if (a != null)
                a.before = b;
            else//如果原本p的后置节点是null，则p就是尾节点。 此时 更新last的引用为 p的前置节点b
                last = b;
            if (last == null) //原本尾节点是null  则，链表中就一个节点
                head = p;
            else {//否则 更新 当前节点p的前置节点为 原尾节点last， last的后置节点是p
                p.before = last;
                last.after = p;
            }
            //尾节点的引用赋值成p
            tail = p;
            //修改modCount。
            ++modCount;
        }
    }
```

#### afterNodeInsertion

afterNodeInsertion方法，在哈希表中插入了一个新节点时调用的，它会把链表的头节点删除掉，删除的方式是通过调用HashMap的removeNode方法。

```java
//回调函数，新节点插入之后回调 ， 根据evict 和   判断是否需要删除最老插入的节点。如果实现LruCache会用到这个方法。
    void afterNodeInsertion(boolean evict) { // possibly remove eldest
        LinkedHashMap.Entry<K,V> first;
        //LinkedHashMap 默认返回false 则不删除节点
        if (evict && (first = head) != null && removeEldestEntry(first)) {
            K key = first.key;
            removeNode(hash(key), key, null, false, true);
        }
    }
    //LinkedHashMap 默认返回false 则不删除节点。 返回true 代表要删除最早的节点。通常构建一个LruCache会在达到Cache的上限是返回true
    protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
        return false;
    }
```

#### afterNodeRemoval

把在HashMap中删除的那个键值对一并从链表中删除，保证了哈希表和链表的一致性。 

```java
//在删除节点e时，同步将e从双向链表上删除
    void afterNodeRemoval(Node<K,V> e) { // unlink
        LinkedHashMap.Entry<K,V> p =
            (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
        //待删除节点 p 的前置后置节点都置空
        p.before = p.after = null;
        //如果前置节点是null，则现在的头结点应该是后置节点a
        if (b == null)
            head = a;
        else//否则将前置节点b的后置节点指向a
            b.after = a;
        //同理如果后置节点时null ，则尾节点应是b
        if (a == null)
            tail = b;
        else//否则更新后置节点a的前置节点为b
            a.before = b;
    }
```

## 遍历

```java
final class LinkedEntryIterator extends LinkedHashIterator
        implements Iterator<Map.Entry<K,V>> {
        public final Map.Entry<K,V> next() { return nextNode(); }
    }

    abstract class LinkedHashIterator {
        //下一个节点
        LinkedHashMap.Entry<K,V> next;
        //当前节点
        LinkedHashMap.Entry<K,V> current;
        int expectedModCount;

        LinkedHashIterator() {
            //初始化时，next 为 LinkedHashMap内部维护的双向链表的扁头
            next = head;
            //记录当前modCount，以满足fail-fast
            expectedModCount = modCount;
            //当前节点为null
            current = null;
        }
        //判断是否还有next
        public final boolean hasNext() {
            //就是判断next是否为null，默认next是head  表头
            return next != null;
        }
        //nextNode() 就是迭代器里的next()方法 。
        //该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。
        final LinkedHashMap.Entry<K,V> nextNode() {
            //记录要返回的e。
            LinkedHashMap.Entry<K,V> e = next;
            //判断fail-fast
            if (modCount != expectedModCount)
                throw new ConcurrentModificationException();
            //如果要返回的节点是null，异常
            if (e == null)
                throw new NoSuchElementException();
            //更新当前节点为e
            current = e;
            //更新下一个节点是e的后置节点
            next = e.after;
            //返回e
            return e;
        }
        //删除方法 最终还是调用了HashMap的removeNode方法
        public final void remove() {
            Node<K,V> p = current;
            if (p == null)
                throw new IllegalStateException();
            if (modCount != expectedModCount)
                throw new ConcurrentModificationException();
            current = null;
            K key = p.key;
            removeNode(hash(key), key, null, false, false);
            expectedModCount = modCount;
        }
    }
```

